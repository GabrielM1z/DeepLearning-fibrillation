{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## CNN (Convolutional Neural Networks)\n",
    "\n",
    "Dans cette partie je vais essayer d'entrainer un CNN pour mon probleme de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps il va falloir créer un code pour arriver à utiliser correctement le dataset donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour standardisé les enregistrement ECG j'ai choisie d'utilisé un zéro padding (ajouté des 0 à la fin de l'enregistrement) pour éviter de supprimer des informations des ECG et pour ne pas rajouter des info qui pourrait fausser les résultats. Le désavantage de cette méthode étant que je me retrouve avec des enregistrement assez gros (18286)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Charger les labels\n",
    "labels_df = pd.read_csv('REFERENCE-v3.csv', header=None)\n",
    "labels_df.columns = ['filename', 'label']\n",
    "\n",
    "# Créer un mapping pour convertir les labels en entiers\n",
    "label_mapping = {'N': 0, 'A': 1, 'O': 2, '~': 3}\n",
    "\n",
    "# Appliquer la conversion des labels\n",
    "labels_df['label'] = labels_df['label'].map(label_mapping)\n",
    "\n",
    "if labels_df['label'].isnull().any():\n",
    "    raise ValueError(\"Certains labels n'ont pas été convertis correctement.\")\n",
    "\n",
    "\n",
    "# Fonction pour charger un fichier ECG au format .mat et appliquer un zero padding si nécessaire\n",
    "# 18286 correspondant a la taille maximale d'un enregistrement\n",
    "def load_ecg(filename, target_length=18286):\n",
    "\n",
    "    mat = scipy.io.loadmat(f'training2017/{filename}.mat')\n",
    "    signal = mat['val'][0]\n",
    "    \n",
    "    # Appliquer le zero padding ou tronquer\n",
    "    if len(signal) < target_length:\n",
    "        pad_size = target_length - len(signal)\n",
    "        signal = np.pad(signal, (0, pad_size), 'constant')\n",
    "    else:\n",
    "        signal = signal[:target_length]\n",
    "    \n",
    "    return signal\n",
    "\n",
    "\n",
    "# Charger tous les signaux ECG et appliquer le zero padding\n",
    "padded_signals = []\n",
    "for filename in labels_df['filename']:\n",
    "    signal = load_ecg(filename)\n",
    "    padded_signals.append(signal)\n",
    "\n",
    "\n",
    "# Convertir en tenseurs PyTorch\n",
    "padded_signals = torch.tensor(padded_signals, dtype=torch.float32)\n",
    "labels = torch.tensor(labels_df['label'].values, dtype=torch.long)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement (80%) et de test (20%)\n",
    "signals_train, signals_test, labels_train, labels_test = train_test_split(padded_signals, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.signals[idx].unsqueeze(0)  # Ajouter une dimension de canal pour CNN\n",
    "        label = self.labels[idx]\n",
    "        return signal, label\n",
    "\n",
    "# Créer les datasets pour l'entraînement et le test\n",
    "train_dataset = ECGDataset(signals_train, labels_train)\n",
    "test_dataset = ECGDataset(signals_test, labels_test)\n",
    "\n",
    "# Créer les DataLoaders pour l'entraînement et le test\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va ensuite devoir établir une architecture pour notre CNN, ici je suis partie sur quelque chose de simple avec 3 couche de convolution entrecoupé de couche de pooling et de reLu pour l'activation ainsi que 2 couches totalement connecté (Linear) à la fin, elles aussi entrecoupé de ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGCNN(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=146240, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ECGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ECGCNN, self).__init__()\n",
    "        \n",
    "        # Première couche convolutionnelle\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, stride=1, padding=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Deuxième couche convolutionnelle\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "        # Troisième couche convolutionnelle\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Fully connected layers (couches denses)\n",
    "        self.fc1 = nn.Linear(64 * (18286 // 8), 128)  # La taille d'entrée dépend du nombre de couches de pooling\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Appliquer la première couche convolutionnelle avec activation et pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # Appliquer la deuxième couche convolutionnelle avec activation et pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Appliquer la troisième couche convolutionnelle avec activation et pooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Aplatir les sorties de la dernière couche convolutionnelle pour les fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Appliquer la première couche fully connected avec ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Appliquer la couche fully connected finale pour la classification\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialiser le modèle\n",
    "model = ECGCNN(num_classes=4)\n",
    "\n",
    "# Afficher l'architecture du modèle\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # Mettre le modèle en mode \"entraînement\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for signals, labels in train_loader:\n",
    "            # Envoyer les données au bon appareil (GPU si disponible)\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Réinitialiser les gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass (calculer les gradients)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Mise à jour des poids\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumuler la perte\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Afficher la perte moyenne pour chaque époque\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Mettre le modèle en mode \"évaluation\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Désactiver la calcul des gradients (inutiles en mode évaluation)\n",
    "        for signals, labels in test_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass (prédictions)\n",
    "            outputs = model(signals)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Calculer le nombre de prédictions correctes\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Afficher la précision (accuracy)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 6.5024\n",
      "Epoch [2/10], Loss: 0.8938\n",
      "Epoch [3/10], Loss: 0.6780\n",
      "Epoch [4/10], Loss: 0.4289\n",
      "Epoch [5/10], Loss: 0.2320\n",
      "Epoch [6/10], Loss: 0.1188\n",
      "Epoch [7/10], Loss: 0.0794\n",
      "Epoch [8/10], Loss: 0.0644\n",
      "Epoch [9/10], Loss: 0.0679\n",
      "Epoch [10/10], Loss: 0.0551\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_model() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m train_model(model, train_loader, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Évaluer le modèle\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate_model() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "# Initialiser le modèle, la fonction de perte et l'optimiseur\n",
    "# Initialiser le modèle, la fonction de perte et l'optimiseur\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ECGCNN(num_classes=4).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Fonction de perte pour la classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimiseur Adam\n",
    "\n",
    "# Entraîner le modèle\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.34%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "evaluate_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
