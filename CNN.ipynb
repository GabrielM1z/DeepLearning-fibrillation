{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## CNN (Convolutional Neural Networks)\n",
    "\n",
    "Dans cette partie je vais essayer d'entrainer un CNN pour mon probleme de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps il va falloir créer un code pour arriver à utiliser correctement le dataset donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datasetResize import *\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filename label\n",
      "0   A00001     N\n",
      "1   A00002     N\n",
      "2   A00003     N\n",
      "3   A00004     A\n",
      "4   A00005     A\n"
     ]
    }
   ],
   "source": [
    "# lecture du excel\n",
    "labels_df = pd.read_csv('REFERENCE-V3.csv', header=None)\n",
    "labels_df.columns = ['filename', 'label']\n",
    "\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger tous les signaux et leurs labels\n",
    "labels = []\n",
    "signals = []\n",
    "signals_padded = []\n",
    "signals_truncated = []\n",
    "signals_interpolated = []\n",
    "\n",
    "# Initialiser avec les paramètres pour le redimensionnement\n",
    "ecg_resizer_max = ECGResizing(target_length=18286)\n",
    "ecg_resizer_med = ECGResizing(target_length=9000)\n",
    "\n",
    "for index, row in labels_df.iterrows():\n",
    "    \n",
    "    labels.append(row['label'])\n",
    "    filename = row['filename']\n",
    "    # Charger un signal ECG\n",
    "    signal = ecg_resizer_max.load_ecg(f'training2017/{filename}.mat')\n",
    "    #signals = np.append(signals,[[signal]])\n",
    "    signals.append(signal)\n",
    "\n",
    "    # Appliquer le zero padding\n",
    "    signal_padded = ecg_resizer_max.resize_signal(signal, method='padding')\n",
    "    signals_padded.append(signal_padded)\n",
    "\n",
    "    # Appliquer le tronquage\n",
    "    signal_truncated = ecg_resizer_med.resize_signal(signal, method='padding')\n",
    "    signals_truncated.append(signal_truncated)\n",
    "\n",
    "    # Appliquer l'interpolation\n",
    "    signal_interpolated = ecg_resizer_med.resize_signal(signal, method='interpolate')\n",
    "    signals_interpolated.append(signal_interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "signals_padded = np.array(signals_padded)\n",
    "signals_truncated = np.array(signals_truncated)\n",
    "signals_interpolated = np.array(signals_interpolated)\n",
    "\n",
    "\n",
    "# Encoder les labels\n",
    "label_mapping = {'N': 0, 'A': 1, 'O': 2, '~': 3}\n",
    "labels_encoded = np.vectorize(label_mapping.get)(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble d'entraînement : (6822, 18286), Ensemble de test : (1706, 18286)\n"
     ]
    }
   ],
   "source": [
    "# Diviser en ensembles d'entraînement et de test\n",
    "X_train_padded, X_test_padded, y_train_padded, y_test_padded = train_test_split(signals_padded, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train_truncated, X_test_truncated, y_train_truncated, y_test_truncated = train_test_split(signals_truncated, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train_interpolated, X_test_interpolated, y_train_interpolated, y_test_interpolated = train_test_split(signals_interpolated, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Afficher les formes des ensembles\n",
    "print(f'Ensemble d\\'entraînement : {X_train_padded.shape}, Ensemble de test : {X_test_padded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = torch.tensor(self.signals[idx], dtype=torch.float32).unsqueeze(0)  # Ajouter la dimension de canal\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return signal, label\n",
    "\n",
    "# Créer des DataLoader pour les signaux interpolés, tronqués ou padded\n",
    "batch_size = 32\n",
    "\n",
    "# padded\n",
    "train_dataset_padded = ECGDataset(X_train_padded, y_train_padded)\n",
    "test_dataset_padded = ECGDataset(X_test_padded, y_test_padded)\n",
    "\n",
    "train_loader_padded = DataLoader(train_dataset_padded, batch_size=batch_size, shuffle=True)\n",
    "test_loader_padded = DataLoader(test_dataset_padded, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# truncate\n",
    "train_dataset_truncated = ECGDataset(X_train_truncated, y_train_truncated)\n",
    "test_dataset_truncated = ECGDataset(X_test_truncated, y_test_truncated)\n",
    "\n",
    "train_loader_truncated = DataLoader(train_dataset_truncated, batch_size=batch_size, shuffle=True)\n",
    "test_loader_truncated = DataLoader(test_dataset_truncated, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# interpolation\n",
    "train_dataset_interpolated = ECGDataset(X_train_interpolated, y_train_interpolated)\n",
    "test_dataset_interpolated = ECGDataset(X_test_interpolated, y_test_interpolated)\n",
    "\n",
    "train_loader_interpolated = DataLoader(train_dataset_interpolated, batch_size=batch_size, shuffle=True)\n",
    "test_loader_interpolated = DataLoader(test_dataset_interpolated, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ECGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4, input_length=9000):  # Suppose que vous avez 4 classes : N, AF, O, ~\n",
    "        super(ECGCNN, self).__init__()\n",
    "        \n",
    "        # Convolutions 1D\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, stride=1, padding=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # pooling\n",
    "        self.pool = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers (MLP)\n",
    "        self.fc1 = nn.Linear(72000, 128)  # Ajustez selon votre entrée après pooling\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten pour les fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECGCNN(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  (fc1): Linear(in_features=72000, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_classes = 4\n",
    "criterion = nn.CrossEntropyLoss()  # Fonction de perte pour la classification multi-classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Initialiser le modèle pour un taille max\n",
    "model_max = ECGCNN(num_classes, 18286)\n",
    "optimizer_max = optim.Adam(model_max.parameters(), lr=0.001)  # Utilisation de l'optimiseur Adam\n",
    "model_max.to(device)\n",
    "\n",
    "# Initialiser le modèle pour un taille médiane\n",
    "model_med_tr = ECGCNN(num_classes, 9000)\n",
    "optimizer_med_tr = optim.Adam(model_med_tr.parameters(), lr=0.001)  # Utilisation de l'optimiseur Adam\n",
    "model_med_tr.to(device)\n",
    "\n",
    "# Initialiser le modèle pour un taille médiane\n",
    "model_med_in = ECGCNN(num_classes, 9000)\n",
    "optimizer_med_in = optim.Adam(model_med_in.parameters(), lr=0.001)  # Utilisation de l'optimiseur Adam\n",
    "model_med_in.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # Mode entraînement\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Remettre les gradients à zéro\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Mise à jour des poids\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calcul de l'accuracy (précision)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calcul de la loss moyenne et de l'accuracy pour cette époque\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_per_class(model, test_loader, class_names):\n",
    "    model.eval()  # Mode évaluation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialiser des variables pour suivre les performances par classe\n",
    "    class_correct = np.zeros(len(class_names))\n",
    "    class_total = np.zeros(len(class_names))\n",
    "    \n",
    "    with torch.no_grad():  # Pas de calcul des gradients en mode évaluation\n",
    "        for signals, labels in test_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Prédictions\n",
    "            outputs = model(signals)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Mettre à jour les valeurs globales\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Calculer les vrais positifs pour chaque classe\n",
    "            for i in range(len(class_names)):\n",
    "                # Sélectionner les indices correspondant à la classe i\n",
    "                idxs = (labels == i)\n",
    "                \n",
    "                # Nombre de vrais positifs pour la classe i\n",
    "                class_correct[i] += (predicted[idxs] == labels[idxs]).sum().item()\n",
    "                \n",
    "                # Nombre total d'exemples de la classe i\n",
    "                class_total[i] += idxs.sum().item()\n",
    "\n",
    "    # Calculer l'accuracy globale\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy globale: {accuracy:.2f}%')\n",
    "\n",
    "    # Calculer et afficher l'accuracy par classe\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if class_total[i] > 0:\n",
    "            class_accuracy = 100 * class_correct[i] / class_total[i]\n",
    "            print(f'Accuracy pour la classe {class_name}: {class_accuracy:.2f}%')\n",
    "        else:\n",
    "            print(f'Pas d\\'exemples pour la classe {class_name} dans l\\'ensemble de test.')\n",
    "\n",
    "# Exemple d'utilisation\n",
    "class_names = ['N', 'AF', 'O', '~']  # Les classes correspondantes à 0, 1, 2, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x146240 and 72000x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle avec les données padded\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[103], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[101], line 28\u001b[0m, in \u001b[0;36mECGCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten pour les fully connected layers\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x146240 and 72000x128)"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle avec les données padded\n",
    "train_model(model_max, train_loader_padded, criterion, optimizer_max, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy globale: 50.00%\n",
      "Accuracy pour la classe N: 67.19%\n",
      "Accuracy pour la classe AF: 3.95%\n",
      "Accuracy pour la classe O: 33.33%\n",
      "Accuracy pour la classe ~: 7.14%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "evaluate_model_per_class(model_max, test_loader_padded, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.6420, Train accuracy: 57.39%\n",
      "Epoch [2/20], Loss: 0.8713, Train accuracy: 62.45%\n",
      "Epoch [3/20], Loss: 0.5959, Train accuracy: 75.32%\n",
      "Epoch [4/20], Loss: 0.2986, Train accuracy: 88.68%\n",
      "Epoch [5/20], Loss: 0.1533, Train accuracy: 94.49%\n",
      "Epoch [6/20], Loss: 0.0822, Train accuracy: 97.60%\n",
      "Epoch [7/20], Loss: 0.0466, Train accuracy: 98.77%\n",
      "Epoch [8/20], Loss: 0.0540, Train accuracy: 98.58%\n",
      "Epoch [9/20], Loss: 0.0659, Train accuracy: 98.07%\n",
      "Epoch [10/20], Loss: 0.0370, Train accuracy: 98.87%\n",
      "Epoch [11/20], Loss: 0.0531, Train accuracy: 98.81%\n",
      "Epoch [12/20], Loss: 0.0361, Train accuracy: 99.06%\n",
      "Epoch [13/20], Loss: 0.0305, Train accuracy: 99.15%\n",
      "Epoch [14/20], Loss: 0.0119, Train accuracy: 99.65%\n",
      "Epoch [15/20], Loss: 0.0170, Train accuracy: 99.69%\n",
      "Epoch [16/20], Loss: 0.0044, Train accuracy: 99.91%\n",
      "Epoch [17/20], Loss: 0.0054, Train accuracy: 99.94%\n",
      "Epoch [18/20], Loss: 0.0013, Train accuracy: 99.96%\n",
      "Epoch [19/20], Loss: 0.0016, Train accuracy: 99.96%\n",
      "Epoch [20/20], Loss: 0.0006, Train accuracy: 99.97%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle avec les données padded + truncated\n",
    "train_model(model_med_tr, train_loader_truncated, criterion, optimizer_med_tr, num_epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy globale: 49.59%\n",
      "Accuracy pour la classe N: 69.66%\n",
      "Accuracy pour la classe AF: 3.95%\n",
      "Accuracy pour la classe O: 27.12%\n",
      "Accuracy pour la classe ~: 3.57%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "evaluate_model_per_class(model_med_tr, test_loader_truncated, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 2.9602, Train accuracy: 56.87%\n",
      "Epoch [2/20], Loss: 0.8674, Train accuracy: 64.12%\n",
      "Epoch [3/20], Loss: 0.5740, Train accuracy: 76.80%\n",
      "Epoch [4/20], Loss: 0.3161, Train accuracy: 87.80%\n",
      "Epoch [5/20], Loss: 0.1685, Train accuracy: 94.42%\n",
      "Epoch [6/20], Loss: 0.1459, Train accuracy: 95.76%\n",
      "Epoch [7/20], Loss: 0.0862, Train accuracy: 97.55%\n",
      "Epoch [8/20], Loss: 0.0633, Train accuracy: 98.26%\n",
      "Epoch [9/20], Loss: 0.0867, Train accuracy: 97.80%\n",
      "Epoch [10/20], Loss: 0.0498, Train accuracy: 98.75%\n",
      "Epoch [11/20], Loss: 0.0500, Train accuracy: 98.84%\n",
      "Epoch [12/20], Loss: 0.0318, Train accuracy: 99.27%\n",
      "Epoch [13/20], Loss: 0.0374, Train accuracy: 99.08%\n",
      "Epoch [14/20], Loss: 0.0639, Train accuracy: 98.30%\n",
      "Epoch [15/20], Loss: 0.0349, Train accuracy: 99.08%\n",
      "Epoch [16/20], Loss: 0.0248, Train accuracy: 99.40%\n",
      "Epoch [17/20], Loss: 0.0271, Train accuracy: 99.49%\n",
      "Epoch [18/20], Loss: 0.0457, Train accuracy: 98.84%\n",
      "Epoch [19/20], Loss: 0.0363, Train accuracy: 99.09%\n",
      "Epoch [20/20], Loss: 0.0317, Train accuracy: 99.30%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle avec les données interpolated\n",
    "train_model(model_med_in, train_loader_interpolated, criterion, optimizer_med_in, num_epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy globale: 49.53%\n",
      "Accuracy pour la classe N: 69.95%\n",
      "Accuracy pour la classe AF: 9.87%\n",
      "Accuracy pour la classe O: 21.95%\n",
      "Accuracy pour la classe ~: 25.00%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "evaluate_model_per_class(model_med_in, test_loader_interpolated, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
