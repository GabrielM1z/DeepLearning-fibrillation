{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datasetResize import *\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filename label\n",
      "0   A00001     N\n",
      "1   A00002     N\n",
      "2   A00003     N\n",
      "3   A00004     A\n",
      "4   A00005     A\n"
     ]
    }
   ],
   "source": [
    "# lecture du excel\n",
    "labels_df = pd.read_csv('REFERENCE-V3.csv', header=None)\n",
    "labels_df.columns = ['filename', 'label']\n",
    "\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger tous les signaux et leurs labels\n",
    "labels = []\n",
    "signals = []\n",
    "signals_padded = []\n",
    "signals_truncated = []\n",
    "signals_interpolated = []\n",
    "\n",
    "# Initialiser avec les paramètres pour le redimensionnement\n",
    "ecg_resizer_max = ECGResizing(target_length=18286)\n",
    "ecg_resizer_med = ECGResizing(target_length=9000)\n",
    "\n",
    "for index, row in labels_df.iterrows():\n",
    "    \n",
    "    labels.append(row['label'])\n",
    "    filename = row['filename']\n",
    "    # Charger un signal ECG\n",
    "    signal = ecg_resizer_max.load_ecg(f'training2017/{filename}.mat')\n",
    "    #signals = np.append(signals,[[signal]])\n",
    "    signals.append(signal)\n",
    "\n",
    "    # Appliquer le zero padding\n",
    "    signal_padded = ecg_resizer_max.resize_signal(signal, method='padding')\n",
    "    signals_padded.append(signal_padded)\n",
    "\n",
    "    # Appliquer le tronquage\n",
    "    signal_truncated = ecg_resizer_med.resize_signal(signal, method='padding')\n",
    "    signals_truncated.append(signal_truncated)\n",
    "\n",
    "    # Appliquer l'interpolation\n",
    "    signal_interpolated = ecg_resizer_med.resize_signal(signal, method='interpolate')\n",
    "    signals_interpolated.append(signal_interpolated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "18286\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "print(len(signals[0]))\n",
    "print(len(signals_padded[0]))\n",
    "print(len(signals_truncated[0]))\n",
    "print(len(signals_interpolated[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "signals_padded = np.array(signals_padded)\n",
    "signals_truncated = np.array(signals_truncated)\n",
    "signals_interpolated = np.array(signals_interpolated)\n",
    "\n",
    "\n",
    "# Encoder les labels\n",
    "label_mapping = {'N': 0, 'A': 1, 'O': 2, '~': 3}\n",
    "labels_encoded = np.vectorize(label_mapping.get)(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble d'entraînement : (6822, 18286), Ensemble de test : (1706, 18286)\n"
     ]
    }
   ],
   "source": [
    "# Diviser en ensembles d'entraînement et de test\n",
    "#X_train_signals, X_test_signals, y_train_signals, y_test_signals = train_test_split(signals, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train_padded, X_test_padded, y_train_padded, y_test_padded = train_test_split(signals_padded, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train_truncated, X_test_truncated, y_train_truncated, y_test_truncated = train_test_split(signals_truncated, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train_interpolated, X_test_interpolated, y_train_interpolated, y_test_interpolated = train_test_split(signals_interpolated, labels_encoded, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Afficher les formes des ensembles\n",
    "print(f'Ensemble d\\'entraînement : {X_train_padded.shape}, Ensemble de test : {X_test_padded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,340,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,340,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,344,996</span> (8.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,344,996\u001b[0m (8.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,344,996</span> (8.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,344,996\u001b[0m (8.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_std_18k = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_padded.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_std_18k.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Résumé du modèle\n",
    "model_std_18k.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2506 - loss: 326.7471 - val_accuracy: 0.2073 - val_loss: 130.1801\n",
      "Epoch 2/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3570 - loss: 52.8116 - val_accuracy: 0.4293 - val_loss: 28.8299\n",
      "Epoch 3/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5825 - loss: 11.3474 - val_accuracy: 0.4806 - val_loss: 17.0228\n",
      "Epoch 4/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5881 - loss: 3.3408 - val_accuracy: 0.4974 - val_loss: 12.1100\n",
      "Epoch 5/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6056 - loss: 2.0985 - val_accuracy: 0.5311 - val_loss: 9.9541\n",
      "Epoch 6/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6427 - loss: 2.0737 - val_accuracy: 0.5267 - val_loss: 9.3018\n",
      "Epoch 7/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6300 - loss: 1.3846 - val_accuracy: 0.5377 - val_loss: 8.2834\n",
      "Epoch 8/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6494 - loss: 1.1498 - val_accuracy: 0.5377 - val_loss: 8.5945\n",
      "Epoch 9/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6548 - loss: 1.1267 - val_accuracy: 0.5407 - val_loss: 8.3603\n",
      "Epoch 10/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6478 - loss: 1.1373 - val_accuracy: 0.5414 - val_loss: 8.3447\n",
      "Epoch 11/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6603 - loss: 1.0913 - val_accuracy: 0.5429 - val_loss: 8.3426\n",
      "Epoch 12/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6541 - loss: 1.1035 - val_accuracy: 0.5429 - val_loss: 8.3546\n",
      "Epoch 13/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6539 - loss: 1.1041 - val_accuracy: 0.5429 - val_loss: 8.3266\n",
      "Epoch 14/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6590 - loss: 1.1354 - val_accuracy: 0.5429 - val_loss: 8.3528\n",
      "Epoch 15/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6444 - loss: 1.1241 - val_accuracy: 0.5421 - val_loss: 8.3693\n",
      "Epoch 16/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6494 - loss: 1.0929 - val_accuracy: 0.5429 - val_loss: 8.3455\n",
      "Epoch 17/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6558 - loss: 1.0815 - val_accuracy: 0.5421 - val_loss: 8.3722\n",
      "Epoch 18/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6231 - loss: 3.0889 - val_accuracy: 0.5641 - val_loss: 5.8489\n",
      "Epoch 19/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6396 - loss: 2.1412 - val_accuracy: 0.5648 - val_loss: 5.8321\n",
      "Epoch 20/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6341 - loss: 1.3496 - val_accuracy: 0.5641 - val_loss: 5.6318\n"
     ]
    }
   ],
   "source": [
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_padded), y=y_train_padded)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model_std_18k.fit(X_train_padded, y_train_padded, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5804 - loss: 11.4943\n",
      "Précision sur l'ensemble de test : 0.5744\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.95      0.73      1015\n",
      "           A       0.00      0.00      0.00       152\n",
      "           O       0.44      0.03      0.06       483\n",
      "           ~       0.10      0.07      0.08        56\n",
      "\n",
      "    accuracy                           0.57      1706\n",
      "   macro avg       0.28      0.26      0.22      1706\n",
      "weighted avg       0.48      0.57      0.46      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_std_18k.evaluate(X_test_padded, y_test_padded)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_std_18k.predict(X_test_padded)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_padded, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,152,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,388</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,156,388\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,388</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,156,388\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Résumé du modèle\n",
    "model_trnctd_9k.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2802 - loss: 486.4412 - val_accuracy: 0.2293 - val_loss: 241.8592\n",
      "Epoch 2/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3088 - loss: 144.2455 - val_accuracy: 0.2117 - val_loss: 108.7142\n",
      "Epoch 3/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3277 - loss: 38.8191 - val_accuracy: 0.2264 - val_loss: 68.0321\n",
      "Epoch 4/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3406 - loss: 21.6743 - val_accuracy: 0.2674 - val_loss: 33.7963\n",
      "Epoch 5/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3889 - loss: 4.0727 - val_accuracy: 0.2755 - val_loss: 29.5019\n",
      "Epoch 6/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3798 - loss: 2.7806 - val_accuracy: 0.2689 - val_loss: 24.3305\n",
      "Epoch 7/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3921 - loss: 3.2617 - val_accuracy: 0.2784 - val_loss: 20.9080\n",
      "Epoch 8/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4909 - loss: 1.3271 - val_accuracy: 0.5040 - val_loss: 19.2417\n",
      "Epoch 9/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6380 - loss: 1.7435 - val_accuracy: 0.5121 - val_loss: 18.9461\n",
      "Epoch 10/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6429 - loss: 1.2688 - val_accuracy: 0.5048 - val_loss: 17.6742\n",
      "Epoch 11/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6397 - loss: 1.3081 - val_accuracy: 0.5158 - val_loss: 16.1811\n",
      "Epoch 12/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6507 - loss: 1.8276 - val_accuracy: 0.5106 - val_loss: 15.8866\n",
      "Epoch 13/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6366 - loss: 1.1027 - val_accuracy: 0.5084 - val_loss: 16.3860\n",
      "Epoch 14/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6459 - loss: 1.1056 - val_accuracy: 0.4989 - val_loss: 16.2013\n",
      "Epoch 15/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6302 - loss: 1.0631 - val_accuracy: 0.5150 - val_loss: 16.4581\n",
      "Epoch 16/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6441 - loss: 1.0512 - val_accuracy: 0.5143 - val_loss: 16.4421\n",
      "Epoch 17/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6464 - loss: 1.0573 - val_accuracy: 0.5121 - val_loss: 16.6255\n",
      "Epoch 18/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6449 - loss: 1.1705 - val_accuracy: 0.5136 - val_loss: 16.5975\n",
      "Epoch 19/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6455 - loss: 1.0595 - val_accuracy: 0.5092 - val_loss: 16.2379\n",
      "Epoch 20/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 1.0332 - val_accuracy: 0.5158 - val_loss: 16.1384\n"
     ]
    }
   ],
   "source": [
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k.fit(X_train_truncated, y_train_truncated, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 15.0817\n",
      "Précision sur l'ensemble de test : 0.5234\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.61      0.83      0.70      1015\n",
      "           A       0.16      0.06      0.09       152\n",
      "           O       0.28      0.07      0.12       483\n",
      "           ~       0.04      0.11      0.06        56\n",
      "\n",
      "    accuracy                           0.52      1706\n",
      "   macro avg       0.27      0.27      0.24      1706\n",
      "weighted avg       0.46      0.52      0.46      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,152,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,388</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,156,388\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,388</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,156,388\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_intrpld_9k = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_intrpld_9k.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Résumé du modèle\n",
    "model_intrpld_9k.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2638 - loss: 569.5490 - val_accuracy: 0.2073 - val_loss: 290.4857\n",
      "Epoch 2/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2917 - loss: 141.2966 - val_accuracy: 0.1700 - val_loss: 80.3658\n",
      "Epoch 3/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2533 - loss: 33.1814 - val_accuracy: 0.1370 - val_loss: 40.1557\n",
      "Epoch 4/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4158 - loss: 6.1644 - val_accuracy: 0.4930 - val_loss: 26.8095\n",
      "Epoch 5/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5901 - loss: 3.8078 - val_accuracy: 0.5165 - val_loss: 22.4784\n",
      "Epoch 6/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6032 - loss: 1.9820 - val_accuracy: 0.5223 - val_loss: 19.8843\n",
      "Epoch 7/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 1.6276 - val_accuracy: 0.5209 - val_loss: 18.5703\n",
      "Epoch 8/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6254 - loss: 1.4602 - val_accuracy: 0.5209 - val_loss: 20.3784\n",
      "Epoch 9/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 1.7066 - val_accuracy: 0.5026 - val_loss: 17.6005\n",
      "Epoch 10/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6143 - loss: 1.7336 - val_accuracy: 0.5114 - val_loss: 18.0254\n",
      "Epoch 11/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 5.1717 - val_accuracy: 0.5209 - val_loss: 17.5973\n",
      "Epoch 12/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5817 - loss: 7.8287 - val_accuracy: 0.5451 - val_loss: 12.0367\n",
      "Epoch 13/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 1.5033 - val_accuracy: 0.5560 - val_loss: 8.9788\n",
      "Epoch 14/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6124 - loss: 1.4069 - val_accuracy: 0.5480 - val_loss: 8.8542\n",
      "Epoch 15/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6161 - loss: 1.3705 - val_accuracy: 0.5487 - val_loss: 8.9439\n",
      "Epoch 16/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6297 - loss: 1.2321 - val_accuracy: 0.5538 - val_loss: 8.8889\n",
      "Epoch 17/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6148 - loss: 1.2462 - val_accuracy: 0.5443 - val_loss: 8.8596\n",
      "Epoch 18/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 1.2305 - val_accuracy: 0.5516 - val_loss: 8.8133\n",
      "Epoch 19/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6153 - loss: 1.1926 - val_accuracy: 0.5531 - val_loss: 8.8013\n",
      "Epoch 20/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: 1.1771 - val_accuracy: 0.5509 - val_loss: 8.7976\n"
     ]
    }
   ],
   "source": [
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_interpolated), y=y_train_interpolated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_interpolated = model_intrpld_9k.fit(X_train_interpolated, y_train_interpolated, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5745 - loss: 7.4100\n",
      "Précision sur l'ensemble de test : 0.5686\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.61      0.92      0.73      1015\n",
      "           A       0.00      0.00      0.00       152\n",
      "           O       0.33      0.06      0.10       483\n",
      "           ~       0.11      0.12      0.12        56\n",
      "\n",
      "    accuracy                           0.57      1706\n",
      "   macro avg       0.26      0.28      0.24      1706\n",
      "weighted avg       0.46      0.57      0.47      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_intrpld_9k.evaluate(X_test_interpolated, y_test_interpolated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_intrpld_9k.predict(X_test_interpolated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_interpolated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification des hyperparamètre sur le truncated 9k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°1 truncated: augmentation du nombre d'epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2383 - loss: 456.1823 - val_accuracy: 0.2630 - val_loss: 241.5354\n",
      "Epoch 2/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3615 - loss: 143.6525 - val_accuracy: 0.2073 - val_loss: 115.6124\n",
      "Epoch 3/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3329 - loss: 43.6283 - val_accuracy: 0.1773 - val_loss: 47.5198\n",
      "Epoch 4/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2899 - loss: 9.1338 - val_accuracy: 0.1788 - val_loss: 32.1455\n",
      "Epoch 5/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2809 - loss: 8.7735 - val_accuracy: 0.1582 - val_loss: 30.2129\n",
      "Epoch 6/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2638 - loss: 6.7166 - val_accuracy: 0.1516 - val_loss: 51.3163\n",
      "Epoch 7/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2401 - loss: 8.4475 - val_accuracy: 0.1370 - val_loss: 21.1251\n",
      "Epoch 8/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2363 - loss: 2.2078 - val_accuracy: 0.1282 - val_loss: 16.5856\n",
      "Epoch 9/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2129 - loss: 2.1942 - val_accuracy: 0.1275 - val_loss: 14.1501\n",
      "Epoch 10/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2324 - loss: 1.2277 - val_accuracy: 0.2996 - val_loss: 13.6511\n",
      "Epoch 11/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4410 - loss: 1.1052 - val_accuracy: 0.5531 - val_loss: 13.5738\n",
      "Epoch 12/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 1.1244 - val_accuracy: 0.5487 - val_loss: 13.5608\n",
      "Epoch 13/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6462 - loss: 1.0767 - val_accuracy: 0.5516 - val_loss: 13.6721\n",
      "Epoch 14/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6622 - loss: 1.1558 - val_accuracy: 0.5553 - val_loss: 13.6000\n",
      "Epoch 15/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 1.1106 - val_accuracy: 0.5443 - val_loss: 13.6080\n",
      "Epoch 16/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 1.1594 - val_accuracy: 0.5436 - val_loss: 13.5630\n",
      "Epoch 17/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6534 - loss: 1.0827 - val_accuracy: 0.5524 - val_loss: 13.5659\n",
      "Epoch 18/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 1.1298 - val_accuracy: 0.5546 - val_loss: 13.5789\n",
      "Epoch 19/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6547 - loss: 1.1140 - val_accuracy: 0.5509 - val_loss: 13.5797\n",
      "Epoch 20/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6520 - loss: 1.1100 - val_accuracy: 0.5495 - val_loss: 13.6034\n",
      "Epoch 21/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 1.1127 - val_accuracy: 0.5480 - val_loss: 13.8593\n",
      "Epoch 22/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6519 - loss: 1.1291 - val_accuracy: 0.5568 - val_loss: 14.0894\n",
      "Epoch 23/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6472 - loss: 1.4615 - val_accuracy: 0.5524 - val_loss: 14.2687\n",
      "Epoch 24/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6226 - loss: 5.1303 - val_accuracy: 0.5685 - val_loss: 8.4283\n",
      "Epoch 25/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6164 - loss: 5.1340 - val_accuracy: 0.5729 - val_loss: 4.1611\n",
      "Epoch 26/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6010 - loss: 1.5267 - val_accuracy: 0.5744 - val_loss: 4.4613\n",
      "Epoch 27/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 3.9198 - val_accuracy: 0.5604 - val_loss: 4.8370\n",
      "Epoch 28/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6120 - loss: 3.4321 - val_accuracy: 0.5707 - val_loss: 2.6400\n",
      "Epoch 29/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5469 - loss: 1.3841 - val_accuracy: 0.2982 - val_loss: 2.5087\n",
      "Epoch 30/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2929 - loss: 1.3924 - val_accuracy: 0.5736 - val_loss: 2.4760\n",
      "Epoch 31/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4222 - loss: 1.3414 - val_accuracy: 0.5773 - val_loss: 2.4543\n",
      "Epoch 32/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 1.3081 - val_accuracy: 0.5700 - val_loss: 2.4780\n",
      "Epoch 33/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4391 - loss: 1.3390 - val_accuracy: 0.5751 - val_loss: 2.4745\n",
      "Epoch 34/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 1.2681 - val_accuracy: 0.5795 - val_loss: 2.4593\n",
      "Epoch 35/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6085 - loss: 1.2957 - val_accuracy: 0.2945 - val_loss: 2.4480\n",
      "Epoch 36/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3013 - loss: 1.3498 - val_accuracy: 0.2945 - val_loss: 2.4344\n",
      "Epoch 37/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3073 - loss: 1.3268 - val_accuracy: 0.2916 - val_loss: 2.4456\n",
      "Epoch 38/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5004 - loss: 1.2816 - val_accuracy: 0.2945 - val_loss: 2.4279\n",
      "Epoch 39/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3290 - loss: 1.3111 - val_accuracy: 0.2945 - val_loss: 2.4036\n",
      "Epoch 40/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3066 - loss: 1.3159 - val_accuracy: 0.2945 - val_loss: 2.4960\n",
      "Epoch 41/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3319 - loss: 1.3188 - val_accuracy: 0.2945 - val_loss: 2.4795\n",
      "Epoch 42/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3352 - loss: 1.2793 - val_accuracy: 0.2945 - val_loss: 2.4886\n",
      "Epoch 43/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3120 - loss: 1.3094 - val_accuracy: 0.5736 - val_loss: 2.5300\n",
      "Epoch 44/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3714 - loss: 1.3458 - val_accuracy: 0.2938 - val_loss: 2.5239\n",
      "Epoch 45/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3267 - loss: 1.3362 - val_accuracy: 0.5780 - val_loss: 2.5013\n",
      "Epoch 46/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6133 - loss: 1.3110 - val_accuracy: 0.2908 - val_loss: 2.5805\n",
      "Epoch 47/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3580 - loss: 1.2767 - val_accuracy: 0.2945 - val_loss: 2.5512\n",
      "Epoch 48/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3055 - loss: 1.3727 - val_accuracy: 0.2908 - val_loss: 2.4884\n",
      "Epoch 49/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3154 - loss: 1.3568 - val_accuracy: 0.5780 - val_loss: 2.2254\n",
      "Epoch 50/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4697 - loss: 1.3327 - val_accuracy: 0.5846 - val_loss: 2.0556\n",
      "Epoch 51/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5676 - loss: 1.3587 - val_accuracy: 0.5868 - val_loss: 1.6825\n",
      "Epoch 52/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5900 - loss: 1.3196 - val_accuracy: 0.5861 - val_loss: 1.6802\n",
      "Epoch 53/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 1.3223 - val_accuracy: 0.5846 - val_loss: 1.6719\n",
      "Epoch 54/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6053 - loss: 1.3409 - val_accuracy: 0.5846 - val_loss: 1.6133\n",
      "Epoch 55/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 1.3388 - val_accuracy: 0.5846 - val_loss: 1.6068\n",
      "Epoch 56/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6163 - loss: 1.3078 - val_accuracy: 0.5846 - val_loss: 1.5996\n",
      "Epoch 57/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6113 - loss: 1.3253 - val_accuracy: 0.5846 - val_loss: 1.5993\n",
      "Epoch 58/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 1.3039 - val_accuracy: 0.5846 - val_loss: 1.5999\n",
      "Epoch 59/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6024 - loss: 1.3214 - val_accuracy: 0.5846 - val_loss: 1.5988\n",
      "Epoch 60/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5964 - loss: 1.3680 - val_accuracy: 0.5846 - val_loss: 1.5981\n",
      "Epoch 61/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6067 - loss: 1.3099 - val_accuracy: 0.5846 - val_loss: 1.5997\n",
      "Epoch 62/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6044 - loss: 1.3232 - val_accuracy: 0.5846 - val_loss: 1.5978\n",
      "Epoch 63/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 1.3306 - val_accuracy: 0.5846 - val_loss: 1.5996\n",
      "Epoch 64/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6040 - loss: 1.3429 - val_accuracy: 0.5846 - val_loss: 1.5998\n",
      "Epoch 65/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 1.3497 - val_accuracy: 0.5846 - val_loss: 1.5995\n",
      "Epoch 66/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6013 - loss: 1.3277 - val_accuracy: 0.5846 - val_loss: 1.5992\n",
      "Epoch 67/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6113 - loss: 1.2935 - val_accuracy: 0.5846 - val_loss: 1.5982\n",
      "Epoch 68/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6091 - loss: 1.3249 - val_accuracy: 0.5846 - val_loss: 1.5962\n",
      "Epoch 69/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 1.3511 - val_accuracy: 0.5868 - val_loss: 1.5933\n",
      "Epoch 70/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6030 - loss: 1.3580 - val_accuracy: 0.5846 - val_loss: 1.6069\n",
      "Epoch 71/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6126 - loss: 1.3262 - val_accuracy: 0.5861 - val_loss: 1.6034\n",
      "Epoch 72/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6011 - loss: 1.3643 - val_accuracy: 0.5861 - val_loss: 1.6011\n",
      "Epoch 73/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 1.3707 - val_accuracy: 0.5861 - val_loss: 1.6024\n",
      "Epoch 74/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6069 - loss: 1.3402 - val_accuracy: 0.5861 - val_loss: 1.6034\n",
      "Epoch 75/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6096 - loss: 1.2938 - val_accuracy: 0.5861 - val_loss: 1.6008\n",
      "Epoch 76/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6102 - loss: 1.3137 - val_accuracy: 0.5861 - val_loss: 1.6049\n",
      "Epoch 77/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 1.3344 - val_accuracy: 0.5861 - val_loss: 1.6031\n",
      "Epoch 78/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6138 - loss: 1.3151 - val_accuracy: 0.5861 - val_loss: 1.6040\n",
      "Epoch 79/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6102 - loss: 1.3041 - val_accuracy: 0.5861 - val_loss: 1.6041\n",
      "Epoch 80/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 1.3306 - val_accuracy: 0.5861 - val_loss: 1.6053\n",
      "Epoch 81/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6125 - loss: 1.3277 - val_accuracy: 0.5861 - val_loss: 1.6039\n",
      "Epoch 82/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 1.3195 - val_accuracy: 0.5861 - val_loss: 1.6045\n",
      "Epoch 83/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6114 - loss: 1.3066 - val_accuracy: 0.5861 - val_loss: 1.6063\n",
      "Epoch 84/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5528 - loss: 1.3175 - val_accuracy: 0.5861 - val_loss: 1.6064\n",
      "Epoch 85/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6053 - loss: 1.3251 - val_accuracy: 0.5861 - val_loss: 1.6055\n",
      "Epoch 86/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6094 - loss: 1.3657 - val_accuracy: 0.5861 - val_loss: 1.6049\n",
      "Epoch 87/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6092 - loss: 1.3347 - val_accuracy: 0.5861 - val_loss: 1.6064\n",
      "Epoch 88/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5404 - loss: 1.2980 - val_accuracy: 0.5861 - val_loss: 1.6051\n",
      "Epoch 89/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6071 - loss: 1.3240 - val_accuracy: 0.5861 - val_loss: 1.6072\n",
      "Epoch 90/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6003 - loss: 1.3373 - val_accuracy: 0.5861 - val_loss: 1.6077\n",
      "Epoch 91/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6131 - loss: 1.2870 - val_accuracy: 0.5861 - val_loss: 1.6062\n",
      "Epoch 92/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 1.3426 - val_accuracy: 0.5861 - val_loss: 1.6069\n",
      "Epoch 93/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6065 - loss: 1.2968 - val_accuracy: 0.5861 - val_loss: 1.6067\n",
      "Epoch 94/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6120 - loss: 1.3513 - val_accuracy: 0.5861 - val_loss: 1.6074\n",
      "Epoch 95/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6107 - loss: 1.3302 - val_accuracy: 0.5861 - val_loss: 1.6075\n",
      "Epoch 96/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5995 - loss: 1.3440 - val_accuracy: 0.5861 - val_loss: 1.6070\n",
      "Epoch 97/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5994 - loss: 1.3494 - val_accuracy: 0.5861 - val_loss: 1.6085\n",
      "Epoch 98/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6005 - loss: 1.3704 - val_accuracy: 0.5861 - val_loss: 1.6064\n",
      "Epoch 99/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 1.3255 - val_accuracy: 0.5861 - val_loss: 1.6068\n",
      "Epoch 100/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6016 - loss: 1.3633 - val_accuracy: 0.5861 - val_loss: 1.6080\n",
      "Epoch 101/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5984 - loss: 1.3505 - val_accuracy: 0.5861 - val_loss: 1.6080\n",
      "Epoch 102/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6142 - loss: 1.2945 - val_accuracy: 0.5861 - val_loss: 1.6088\n",
      "Epoch 103/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6132 - loss: 1.3310 - val_accuracy: 0.5861 - val_loss: 1.6097\n",
      "Epoch 104/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6181 - loss: 1.2988 - val_accuracy: 0.5861 - val_loss: 1.6106\n",
      "Epoch 105/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6100 - loss: 1.3027 - val_accuracy: 0.5861 - val_loss: 1.6092\n",
      "Epoch 106/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6023 - loss: 1.3263 - val_accuracy: 0.5861 - val_loss: 1.6113\n",
      "Epoch 107/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6017 - loss: 1.3209 - val_accuracy: 0.5861 - val_loss: 1.6126\n",
      "Epoch 108/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6126 - loss: 1.3165 - val_accuracy: 0.5861 - val_loss: 1.6121\n",
      "Epoch 109/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5994 - loss: 1.3575 - val_accuracy: 0.5861 - val_loss: 1.6117\n",
      "Epoch 110/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5964 - loss: 1.3551 - val_accuracy: 0.5861 - val_loss: 1.6097\n",
      "Epoch 111/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6117 - loss: 1.3192 - val_accuracy: 0.5861 - val_loss: 1.6105\n",
      "Epoch 112/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6043 - loss: 1.3282 - val_accuracy: 0.5861 - val_loss: 1.6097\n",
      "Epoch 113/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6079 - loss: 1.3369 - val_accuracy: 0.5861 - val_loss: 1.6102\n",
      "Epoch 114/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6041 - loss: 1.3117 - val_accuracy: 0.5861 - val_loss: 1.6111\n",
      "Epoch 115/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6118 - loss: 1.3462 - val_accuracy: 0.5861 - val_loss: 1.6120\n",
      "Epoch 116/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6031 - loss: 1.3306 - val_accuracy: 0.5861 - val_loss: 1.6121\n",
      "Epoch 117/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 1.3286 - val_accuracy: 0.5861 - val_loss: 1.6115\n",
      "Epoch 118/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6199 - loss: 1.3371 - val_accuracy: 0.5861 - val_loss: 1.6144\n",
      "Epoch 119/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 1.3160 - val_accuracy: 0.5861 - val_loss: 1.6129\n",
      "Epoch 120/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6100 - loss: 1.3347 - val_accuracy: 0.5861 - val_loss: 1.6118\n",
      "Epoch 121/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6149 - loss: 1.2985 - val_accuracy: 0.5861 - val_loss: 1.6132\n",
      "Epoch 122/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6117 - loss: 1.3225 - val_accuracy: 0.5861 - val_loss: 1.6131\n",
      "Epoch 123/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 1.3343 - val_accuracy: 0.5861 - val_loss: 1.6138\n",
      "Epoch 124/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6011 - loss: 1.3679 - val_accuracy: 0.5861 - val_loss: 1.6142\n",
      "Epoch 125/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 1.3406 - val_accuracy: 0.5861 - val_loss: 1.6141\n",
      "Epoch 126/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6103 - loss: 1.2668 - val_accuracy: 0.5861 - val_loss: 1.6130\n",
      "Epoch 127/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6158 - loss: 1.3103 - val_accuracy: 0.5861 - val_loss: 1.6145\n",
      "Epoch 128/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 1.3409 - val_accuracy: 0.5861 - val_loss: 1.6152\n",
      "Epoch 129/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 1.3447 - val_accuracy: 0.5861 - val_loss: 1.6153\n",
      "Epoch 130/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 1.3317 - val_accuracy: 0.5861 - val_loss: 1.6139\n",
      "Epoch 131/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6045 - loss: 1.3203 - val_accuracy: 0.5861 - val_loss: 1.6138\n",
      "Epoch 132/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6088 - loss: 1.3591 - val_accuracy: 0.5861 - val_loss: 1.6143\n",
      "Epoch 133/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6061 - loss: 1.3030 - val_accuracy: 0.5861 - val_loss: 1.6148\n",
      "Epoch 134/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6141 - loss: 1.2819 - val_accuracy: 0.5861 - val_loss: 1.6158\n",
      "Epoch 135/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 1.3472 - val_accuracy: 0.5861 - val_loss: 1.6161\n",
      "Epoch 136/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6114 - loss: 1.3117 - val_accuracy: 0.5861 - val_loss: 1.6144\n",
      "Epoch 137/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 1.3586 - val_accuracy: 0.5861 - val_loss: 1.6176\n",
      "Epoch 138/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5386 - loss: 1.3716 - val_accuracy: 0.5861 - val_loss: 1.6163\n",
      "Epoch 139/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6098 - loss: 1.2832 - val_accuracy: 0.5861 - val_loss: 1.6154\n",
      "Epoch 140/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6135 - loss: 1.3255 - val_accuracy: 0.5861 - val_loss: 1.6174\n",
      "Epoch 141/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5565 - loss: 1.3513 - val_accuracy: 0.5861 - val_loss: 1.6175\n",
      "Epoch 142/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6083 - loss: 1.3176 - val_accuracy: 0.5861 - val_loss: 1.6177\n",
      "Epoch 143/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6155 - loss: 1.3054 - val_accuracy: 0.5861 - val_loss: 1.6180\n",
      "Epoch 144/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6064 - loss: 1.3118 - val_accuracy: 0.5861 - val_loss: 1.6179\n",
      "Epoch 145/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6034 - loss: 1.3517 - val_accuracy: 0.5861 - val_loss: 1.6185\n",
      "Epoch 146/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6064 - loss: 1.2960 - val_accuracy: 0.5861 - val_loss: 1.6185\n",
      "Epoch 147/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6114 - loss: 1.3473 - val_accuracy: 0.5861 - val_loss: 1.6203\n",
      "Epoch 148/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6085 - loss: 1.3063 - val_accuracy: 0.5861 - val_loss: 1.6206\n",
      "Epoch 149/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6068 - loss: 1.3335 - val_accuracy: 0.5861 - val_loss: 1.6189\n",
      "Epoch 150/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6001 - loss: 1.3196 - val_accuracy: 0.5861 - val_loss: 1.6205\n",
      "Epoch 151/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6140 - loss: 1.3419 - val_accuracy: 0.5861 - val_loss: 1.6200\n",
      "Epoch 152/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5967 - loss: 1.3494 - val_accuracy: 0.5861 - val_loss: 1.6210\n",
      "Epoch 153/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6064 - loss: 1.3428 - val_accuracy: 0.5861 - val_loss: 1.6185\n",
      "Epoch 154/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6046 - loss: 1.3019 - val_accuracy: 0.5861 - val_loss: 1.6202\n",
      "Epoch 155/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6051 - loss: 1.3525 - val_accuracy: 0.5861 - val_loss: 1.6217\n",
      "Epoch 156/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6193 - loss: 1.3005 - val_accuracy: 0.5861 - val_loss: 1.6192\n",
      "Epoch 157/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 1.3481 - val_accuracy: 0.5861 - val_loss: 1.6217\n",
      "Epoch 158/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6140 - loss: 1.3194 - val_accuracy: 0.5861 - val_loss: 1.6198\n",
      "Epoch 159/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6070 - loss: 1.3140 - val_accuracy: 0.5861 - val_loss: 1.6236\n",
      "Epoch 160/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6184 - loss: 1.3221 - val_accuracy: 0.5861 - val_loss: 1.6223\n",
      "Epoch 161/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6047 - loss: 1.3754 - val_accuracy: 0.5861 - val_loss: 1.6228\n",
      "Epoch 162/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6110 - loss: 1.3068 - val_accuracy: 0.5861 - val_loss: 1.6231\n",
      "Epoch 163/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.3225 - val_accuracy: 0.5861 - val_loss: 1.6230\n",
      "Epoch 164/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 1.3518 - val_accuracy: 0.5861 - val_loss: 1.6242\n",
      "Epoch 165/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6144 - loss: 1.2884 - val_accuracy: 0.5861 - val_loss: 1.6233\n",
      "Epoch 166/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 1.3234 - val_accuracy: 0.5861 - val_loss: 1.6273\n",
      "Epoch 167/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6039 - loss: 1.3448 - val_accuracy: 0.5861 - val_loss: 1.6271\n",
      "Epoch 168/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6029 - loss: 1.3474 - val_accuracy: 0.5861 - val_loss: 1.6276\n",
      "Epoch 169/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 1.3521 - val_accuracy: 0.5861 - val_loss: 1.6279\n",
      "Epoch 170/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6051 - loss: 1.3051 - val_accuracy: 0.5685 - val_loss: 8.2078\n",
      "Epoch 171/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5880 - loss: 3.7411 - val_accuracy: 0.5905 - val_loss: 1.7001\n",
      "Epoch 172/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5997 - loss: 1.4708 - val_accuracy: 0.5919 - val_loss: 1.6673\n",
      "Epoch 173/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5737 - loss: 1.4115 - val_accuracy: 0.5919 - val_loss: 1.6401\n",
      "Epoch 174/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4733 - loss: 1.3387 - val_accuracy: 0.0828 - val_loss: 1.6561\n",
      "Epoch 175/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0907 - loss: 1.4092 - val_accuracy: 0.0828 - val_loss: 1.6567\n",
      "Epoch 176/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0898 - loss: 1.3675 - val_accuracy: 0.0828 - val_loss: 1.6594\n",
      "Epoch 177/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2758 - loss: 1.3342 - val_accuracy: 0.0828 - val_loss: 1.6606\n",
      "Epoch 178/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0939 - loss: 1.3491 - val_accuracy: 0.0828 - val_loss: 1.6605\n",
      "Epoch 179/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0898 - loss: 1.3730 - val_accuracy: 0.0828 - val_loss: 1.6628\n",
      "Epoch 180/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0947 - loss: 1.3954 - val_accuracy: 0.0828 - val_loss: 1.6625\n",
      "Epoch 181/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0924 - loss: 1.3838 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 182/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0860 - loss: 1.3645 - val_accuracy: 0.0828 - val_loss: 1.6600\n",
      "Epoch 183/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1123 - loss: 1.3949 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 184/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0955 - loss: 1.3808 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 185/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0897 - loss: 1.4152 - val_accuracy: 0.0828 - val_loss: 1.6617\n",
      "Epoch 186/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0873 - loss: 1.4328 - val_accuracy: 0.0828 - val_loss: 1.6605\n",
      "Epoch 187/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0930 - loss: 1.4084 - val_accuracy: 0.0828 - val_loss: 1.6603\n",
      "Epoch 188/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0914 - loss: 1.3981 - val_accuracy: 0.0828 - val_loss: 1.6620\n",
      "Epoch 189/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1009 - loss: 1.3634 - val_accuracy: 0.0828 - val_loss: 1.6606\n",
      "Epoch 190/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 1.3705 - val_accuracy: 0.0828 - val_loss: 1.6599\n",
      "Epoch 191/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0891 - loss: 1.3699 - val_accuracy: 0.0828 - val_loss: 1.6615\n",
      "Epoch 192/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0851 - loss: 1.3728 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 193/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0831 - loss: 1.3803 - val_accuracy: 0.0828 - val_loss: 1.6648\n",
      "Epoch 194/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0919 - loss: 1.3719 - val_accuracy: 0.0828 - val_loss: 1.6643\n",
      "Epoch 195/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1504 - loss: 1.3807 - val_accuracy: 0.0828 - val_loss: 1.6635\n",
      "Epoch 196/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0907 - loss: 1.4418 - val_accuracy: 0.0828 - val_loss: 1.6637\n",
      "Epoch 197/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0936 - loss: 1.4285 - val_accuracy: 0.0828 - val_loss: 1.6602\n",
      "Epoch 198/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1161 - loss: 1.3289 - val_accuracy: 0.0828 - val_loss: 1.6596\n",
      "Epoch 199/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0966 - loss: 1.4022 - val_accuracy: 0.0828 - val_loss: 1.6632\n",
      "Epoch 200/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0951 - loss: 1.3920 - val_accuracy: 0.0828 - val_loss: 1.6617\n",
      "Epoch 201/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0926 - loss: 1.3892 - val_accuracy: 0.0828 - val_loss: 1.6614\n",
      "Epoch 202/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0926 - loss: 1.3941 - val_accuracy: 0.0828 - val_loss: 1.6620\n",
      "Epoch 203/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0932 - loss: 1.3982 - val_accuracy: 0.0828 - val_loss: 1.6608\n",
      "Epoch 204/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0913 - loss: 1.3910 - val_accuracy: 0.0828 - val_loss: 1.6589\n",
      "Epoch 205/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2088 - loss: 1.3698 - val_accuracy: 0.0828 - val_loss: 1.6613\n",
      "Epoch 206/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0916 - loss: 1.3984 - val_accuracy: 0.0828 - val_loss: 1.6614\n",
      "Epoch 207/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0906 - loss: 1.4200 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 208/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1989 - loss: 1.3506 - val_accuracy: 0.0828 - val_loss: 1.6604\n",
      "Epoch 209/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0913 - loss: 1.3849 - val_accuracy: 0.0828 - val_loss: 1.6630\n",
      "Epoch 210/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1834 - loss: 1.3852 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 211/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0883 - loss: 1.4191 - val_accuracy: 0.0828 - val_loss: 1.6620\n",
      "Epoch 212/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0875 - loss: 1.3937 - val_accuracy: 0.0828 - val_loss: 1.6634\n",
      "Epoch 213/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0908 - loss: 1.3708 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 214/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0906 - loss: 1.3464 - val_accuracy: 0.0828 - val_loss: 1.6619\n",
      "Epoch 215/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0938 - loss: 1.3442 - val_accuracy: 0.0828 - val_loss: 1.6628\n",
      "Epoch 216/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0985 - loss: 1.3751 - val_accuracy: 0.0828 - val_loss: 1.6612\n",
      "Epoch 217/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1187 - loss: 1.3699 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 218/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0915 - loss: 1.3620 - val_accuracy: 0.0828 - val_loss: 1.6640\n",
      "Epoch 219/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0862 - loss: 1.3749 - val_accuracy: 0.0828 - val_loss: 1.6638\n",
      "Epoch 220/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0911 - loss: 1.4080 - val_accuracy: 0.0828 - val_loss: 1.6628\n",
      "Epoch 221/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0947 - loss: 1.4094 - val_accuracy: 0.0828 - val_loss: 1.6616\n",
      "Epoch 222/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0935 - loss: 1.4273 - val_accuracy: 0.0828 - val_loss: 1.6611\n",
      "Epoch 223/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0919 - loss: 1.3804 - val_accuracy: 0.0828 - val_loss: 1.6602\n",
      "Epoch 224/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0894 - loss: 1.3787 - val_accuracy: 0.0828 - val_loss: 1.6626\n",
      "Epoch 225/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3064 - loss: 1.3189 - val_accuracy: 0.0828 - val_loss: 1.6613\n",
      "Epoch 226/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0909 - loss: 1.4389 - val_accuracy: 0.0828 - val_loss: 1.6643\n",
      "Epoch 227/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0980 - loss: 1.4319 - val_accuracy: 0.0828 - val_loss: 1.6625\n",
      "Epoch 228/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0918 - loss: 1.3872 - val_accuracy: 0.0828 - val_loss: 1.6615\n",
      "Epoch 229/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1065 - loss: 1.3582 - val_accuracy: 0.0828 - val_loss: 1.6614\n",
      "Epoch 230/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1270 - loss: 1.3751 - val_accuracy: 0.0828 - val_loss: 1.6622\n",
      "Epoch 231/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1046 - loss: 1.3704 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 232/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0874 - loss: 1.3214 - val_accuracy: 0.0828 - val_loss: 1.6624\n",
      "Epoch 233/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0863 - loss: 1.3497 - val_accuracy: 0.0828 - val_loss: 1.6647\n",
      "Epoch 234/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0892 - loss: 1.3731 - val_accuracy: 0.0828 - val_loss: 1.6634\n",
      "Epoch 235/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 1.3963 - val_accuracy: 0.0828 - val_loss: 1.6631\n",
      "Epoch 236/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0910 - loss: 1.4117 - val_accuracy: 0.0828 - val_loss: 1.6630\n",
      "Epoch 237/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0914 - loss: 1.3758 - val_accuracy: 0.0828 - val_loss: 1.6629\n",
      "Epoch 238/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0897 - loss: 1.3830 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 239/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0908 - loss: 1.3701 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 240/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0942 - loss: 1.3936 - val_accuracy: 0.0828 - val_loss: 1.6605\n",
      "Epoch 241/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1021 - loss: 1.4119 - val_accuracy: 0.0828 - val_loss: 1.6619\n",
      "Epoch 242/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0934 - loss: 1.3831 - val_accuracy: 0.0828 - val_loss: 1.6629\n",
      "Epoch 243/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0896 - loss: 1.4090 - val_accuracy: 0.0828 - val_loss: 1.6609\n",
      "Epoch 244/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1233 - loss: 1.3978 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 245/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0949 - loss: 1.3925 - val_accuracy: 0.0828 - val_loss: 1.6619\n",
      "Epoch 246/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0940 - loss: 1.3976 - val_accuracy: 0.0828 - val_loss: 1.6611\n",
      "Epoch 247/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2912 - loss: 1.3477 - val_accuracy: 0.0828 - val_loss: 1.6616\n",
      "Epoch 248/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3106 - loss: 1.3609 - val_accuracy: 0.0828 - val_loss: 1.6617\n",
      "Epoch 249/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0846 - loss: 1.3722 - val_accuracy: 0.0828 - val_loss: 1.6649\n",
      "Epoch 250/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0927 - loss: 1.3404 - val_accuracy: 0.0828 - val_loss: 1.6613\n",
      "Epoch 251/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0955 - loss: 1.4427 - val_accuracy: 0.0828 - val_loss: 1.6638\n",
      "Epoch 252/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0894 - loss: 1.3674 - val_accuracy: 0.0828 - val_loss: 1.6622\n",
      "Epoch 253/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0892 - loss: 1.3496 - val_accuracy: 0.0828 - val_loss: 1.6615\n",
      "Epoch 254/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0884 - loss: 1.4496 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 255/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2710 - loss: 1.4082 - val_accuracy: 0.0828 - val_loss: 1.6607\n",
      "Epoch 256/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0943 - loss: 1.3896 - val_accuracy: 0.0828 - val_loss: 1.6611\n",
      "Epoch 257/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0935 - loss: 1.3746 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 258/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0914 - loss: 1.4301 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 259/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1415 - loss: 1.3121 - val_accuracy: 0.0828 - val_loss: 1.6612\n",
      "Epoch 260/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1057 - loss: 1.3808 - val_accuracy: 0.0828 - val_loss: 1.6630\n",
      "Epoch 261/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0911 - loss: 1.3707 - val_accuracy: 0.0828 - val_loss: 1.6627\n",
      "Epoch 262/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0883 - loss: 1.3429 - val_accuracy: 0.0828 - val_loss: 1.6632\n",
      "Epoch 263/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0939 - loss: 1.3975 - val_accuracy: 0.0828 - val_loss: 1.6628\n",
      "Epoch 264/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0946 - loss: 1.3760 - val_accuracy: 0.0828 - val_loss: 1.6611\n",
      "Epoch 265/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0918 - loss: 1.3718 - val_accuracy: 0.0828 - val_loss: 1.6616\n",
      "Epoch 266/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0868 - loss: 1.3771 - val_accuracy: 0.0828 - val_loss: 1.6615\n",
      "Epoch 267/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0900 - loss: 1.3905 - val_accuracy: 0.0828 - val_loss: 1.6640\n",
      "Epoch 268/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0877 - loss: 1.4059 - val_accuracy: 0.0828 - val_loss: 1.6617\n",
      "Epoch 269/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0931 - loss: 1.4412 - val_accuracy: 0.0828 - val_loss: 1.6616\n",
      "Epoch 270/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1028 - loss: 1.3906 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 271/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0931 - loss: 1.4066 - val_accuracy: 0.0828 - val_loss: 1.6615\n",
      "Epoch 272/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0945 - loss: 1.3755 - val_accuracy: 0.0828 - val_loss: 1.6605\n",
      "Epoch 273/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0966 - loss: 1.4027 - val_accuracy: 0.0828 - val_loss: 1.6607\n",
      "Epoch 274/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1059 - loss: 1.4109 - val_accuracy: 0.0828 - val_loss: 1.6618\n",
      "Epoch 275/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1089 - loss: 1.3615 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 276/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1579 - loss: 1.3821 - val_accuracy: 0.0828 - val_loss: 1.6599\n",
      "Epoch 277/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0881 - loss: 1.3797 - val_accuracy: 0.0828 - val_loss: 1.6622\n",
      "Epoch 278/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0842 - loss: 1.3574 - val_accuracy: 0.0828 - val_loss: 1.6610\n",
      "Epoch 279/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1364 - loss: 1.3852 - val_accuracy: 0.0828 - val_loss: 1.6620\n",
      "Epoch 280/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0954 - loss: 1.4073 - val_accuracy: 0.0828 - val_loss: 1.6602\n",
      "Epoch 281/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0939 - loss: 1.4086 - val_accuracy: 0.0828 - val_loss: 1.6621\n",
      "Epoch 282/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0938 - loss: 1.3712 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 283/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2218 - loss: 1.3847 - val_accuracy: 0.0828 - val_loss: 1.6615\n",
      "Epoch 284/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1211 - loss: 1.3961 - val_accuracy: 0.0828 - val_loss: 1.6598\n",
      "Epoch 285/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0922 - loss: 1.4075 - val_accuracy: 0.0828 - val_loss: 1.6617\n",
      "Epoch 286/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0915 - loss: 1.3862 - val_accuracy: 0.0828 - val_loss: 1.6612\n",
      "Epoch 287/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1046 - loss: 1.3845 - val_accuracy: 0.0828 - val_loss: 1.6607\n",
      "Epoch 288/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1089 - loss: 1.3505 - val_accuracy: 0.0828 - val_loss: 1.6616\n",
      "Epoch 289/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0952 - loss: 1.4032 - val_accuracy: 0.0828 - val_loss: 1.6648\n",
      "Epoch 290/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 1.3813 - val_accuracy: 0.0828 - val_loss: 1.6622\n",
      "Epoch 291/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0947 - loss: 1.4102 - val_accuracy: 0.0828 - val_loss: 1.6605\n",
      "Epoch 292/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1577 - loss: 1.3729 - val_accuracy: 0.0828 - val_loss: 1.6605\n",
      "Epoch 293/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1828 - loss: 1.3529 - val_accuracy: 0.0828 - val_loss: 1.6623\n",
      "Epoch 294/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0870 - loss: 1.3248 - val_accuracy: 0.0828 - val_loss: 1.6636\n",
      "Epoch 295/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0893 - loss: 1.3638 - val_accuracy: 0.0828 - val_loss: 1.6627\n",
      "Epoch 296/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0909 - loss: 1.4574 - val_accuracy: 0.0828 - val_loss: 1.6633\n",
      "Epoch 297/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0902 - loss: 1.4144 - val_accuracy: 0.0828 - val_loss: 1.6613\n",
      "Epoch 298/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0867 - loss: 1.3912 - val_accuracy: 0.0828 - val_loss: 1.6625\n",
      "Epoch 299/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0872 - loss: 1.3572 - val_accuracy: 0.0828 - val_loss: 1.6631\n",
      "Epoch 300/300\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0952 - loss: 1.4497 - val_accuracy: 0.0828 - val_loss: 1.6605\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k_test1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k_test1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k_test1.fit(X_train_truncated, y_train_truncated, epochs=300, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0941 - loss: 1.4409\n",
      "Précision sur l'ensemble de test : 0.0891\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00      1015\n",
      "           A       0.09      0.99      0.16       152\n",
      "           O       1.00      0.00      0.00       483\n",
      "           ~       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.09      1706\n",
      "   macro avg       0.27      0.25      0.04      1706\n",
      "weighted avg       0.29      0.09      0.02      1706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k_test1.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k_test1.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°2 truncated: Nombre d'epoch optimum (90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2421 - loss: 465.5719 - val_accuracy: 0.1985 - val_loss: 237.5749\n",
      "Epoch 2/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2553 - loss: 120.9290 - val_accuracy: 0.3011 - val_loss: 90.7833\n",
      "Epoch 3/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4193 - loss: 35.4246 - val_accuracy: 0.3795 - val_loss: 50.4660\n",
      "Epoch 4/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5246 - loss: 15.8973 - val_accuracy: 0.4242 - val_loss: 29.8360\n",
      "Epoch 5/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5521 - loss: 7.5090 - val_accuracy: 0.4769 - val_loss: 23.0603\n",
      "Epoch 6/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6004 - loss: 4.2848 - val_accuracy: 0.4982 - val_loss: 18.8109\n",
      "Epoch 7/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6286 - loss: 1.4980 - val_accuracy: 0.4974 - val_loss: 17.4702\n",
      "Epoch 8/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6412 - loss: 1.3290 - val_accuracy: 0.5077 - val_loss: 16.9651\n",
      "Epoch 9/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6312 - loss: 2.1088 - val_accuracy: 0.4879 - val_loss: 22.7353\n",
      "Epoch 10/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5911 - loss: 2.9001 - val_accuracy: 0.5106 - val_loss: 15.4289\n",
      "Epoch 11/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6313 - loss: 1.3854 - val_accuracy: 0.5128 - val_loss: 13.8508\n",
      "Epoch 12/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6354 - loss: 1.3960 - val_accuracy: 0.5121 - val_loss: 14.0509\n",
      "Epoch 13/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6356 - loss: 1.4242 - val_accuracy: 0.5194 - val_loss: 13.2931\n",
      "Epoch 14/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6313 - loss: 1.1805 - val_accuracy: 0.5209 - val_loss: 13.0924\n",
      "Epoch 15/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6441 - loss: 1.0788 - val_accuracy: 0.5143 - val_loss: 13.1421\n",
      "Epoch 16/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6480 - loss: 1.0604 - val_accuracy: 0.5223 - val_loss: 13.0749\n",
      "Epoch 17/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6665 - loss: 1.0554 - val_accuracy: 0.5150 - val_loss: 13.9857\n",
      "Epoch 18/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6652 - loss: 1.0200 - val_accuracy: 0.5223 - val_loss: 14.0686\n",
      "Epoch 19/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6555 - loss: 1.0570 - val_accuracy: 0.5245 - val_loss: 13.9653\n",
      "Epoch 20/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 1.0144 - val_accuracy: 0.5150 - val_loss: 13.9830\n",
      "Epoch 21/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6672 - loss: 1.0133 - val_accuracy: 0.5187 - val_loss: 13.9059\n",
      "Epoch 22/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6594 - loss: 1.0576 - val_accuracy: 0.5238 - val_loss: 14.3656\n",
      "Epoch 23/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6600 - loss: 1.0357 - val_accuracy: 0.5121 - val_loss: 14.4364\n",
      "Epoch 24/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 1.0582 - val_accuracy: 0.5158 - val_loss: 14.3546\n",
      "Epoch 25/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 1.0677 - val_accuracy: 0.5231 - val_loss: 14.4993\n",
      "Epoch 26/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6644 - loss: 1.0031 - val_accuracy: 0.5194 - val_loss: 14.8840\n",
      "Epoch 27/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6222 - loss: 3.8881 - val_accuracy: 0.5319 - val_loss: 12.3457\n",
      "Epoch 28/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 6.7061 - val_accuracy: 0.5678 - val_loss: 5.1347\n",
      "Epoch 29/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6026 - loss: 4.3447 - val_accuracy: 0.5722 - val_loss: 3.5377\n",
      "Epoch 30/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5935 - loss: 9.3528 - val_accuracy: 0.5853 - val_loss: 3.3982\n",
      "Epoch 31/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5952 - loss: 3.5941 - val_accuracy: 0.5846 - val_loss: 2.8449\n",
      "Epoch 32/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6023 - loss: 1.3888 - val_accuracy: 0.5861 - val_loss: 2.7329\n",
      "Epoch 33/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 1.3079 - val_accuracy: 0.5868 - val_loss: 2.6565\n",
      "Epoch 34/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4677 - loss: 1.3071 - val_accuracy: 0.0842 - val_loss: 2.6673\n",
      "Epoch 35/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1038 - loss: 1.3614 - val_accuracy: 0.0857 - val_loss: 2.6658\n",
      "Epoch 36/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1056 - loss: 1.3537 - val_accuracy: 0.0857 - val_loss: 2.6747\n",
      "Epoch 37/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1630 - loss: 1.3678 - val_accuracy: 0.0857 - val_loss: 2.6839\n",
      "Epoch 38/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1056 - loss: 1.3602 - val_accuracy: 0.0857 - val_loss: 2.6796\n",
      "Epoch 39/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1031 - loss: 1.3459 - val_accuracy: 0.0850 - val_loss: 2.7075\n",
      "Epoch 40/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1173 - loss: 1.3674 - val_accuracy: 0.0842 - val_loss: 2.6960\n",
      "Epoch 41/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1101 - loss: 1.3409 - val_accuracy: 0.0842 - val_loss: 2.6914\n",
      "Epoch 42/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5341 - loss: 1.3047 - val_accuracy: 0.0850 - val_loss: 2.6877\n",
      "Epoch 43/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1130 - loss: 1.3269 - val_accuracy: 0.5861 - val_loss: 2.6900\n",
      "Epoch 44/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5735 - loss: 1.3308 - val_accuracy: 0.0850 - val_loss: 2.6890\n",
      "Epoch 45/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1353 - loss: 1.3417 - val_accuracy: 0.5861 - val_loss: 2.6871\n",
      "Epoch 46/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5299 - loss: 1.2911 - val_accuracy: 0.5861 - val_loss: 2.6840\n",
      "Epoch 47/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3851 - loss: 1.3119 - val_accuracy: 0.0864 - val_loss: 2.7308\n",
      "Epoch 48/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1184 - loss: 1.3248 - val_accuracy: 0.0857 - val_loss: 2.7396\n",
      "Epoch 49/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4239 - loss: 1.4398 - val_accuracy: 0.5861 - val_loss: 2.5639\n",
      "Epoch 50/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2828 - loss: 1.4217 - val_accuracy: 0.5883 - val_loss: 2.6027\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k_test2 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k_test2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k_test2.fit(X_train_truncated, y_train_truncated, epochs=50, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5913 - loss: 2.9774\n",
      "Précision sur l'ensemble de test : 0.5897\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.99      0.74      1015\n",
      "           A       0.25      0.01      0.01       152\n",
      "           O       0.14      0.00      0.00       483\n",
      "           ~       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.59      1706\n",
      "   macro avg       0.25      0.25      0.19      1706\n",
      "weighted avg       0.42      0.59      0.45      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k_test2.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k_test2.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°3 truncated: Augmentation du nombre de couches (de une à deux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,152,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,162,596</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,162,596\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,162,596</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,162,596\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2729 - loss: 201.0033 - val_accuracy: 0.2505 - val_loss: 64.1274\n",
      "Epoch 2/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2510 - loss: 64.1378 - val_accuracy: 0.2088 - val_loss: 26.4301\n",
      "Epoch 3/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2398 - loss: 17.3160 - val_accuracy: 0.2960 - val_loss: 14.6310\n",
      "Epoch 4/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3754 - loss: 6.9054 - val_accuracy: 0.4366 - val_loss: 7.2112\n",
      "Epoch 5/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4624 - loss: 1.7627 - val_accuracy: 0.5648 - val_loss: 4.9453\n",
      "Epoch 6/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 1.6756 - val_accuracy: 0.4403 - val_loss: 5.5533\n",
      "Epoch 7/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4893 - loss: 1.4484 - val_accuracy: 0.5421 - val_loss: 4.8342\n",
      "Epoch 8/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5140 - loss: 1.3571 - val_accuracy: 0.4571 - val_loss: 4.4259\n",
      "Epoch 9/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4853 - loss: 1.2291 - val_accuracy: 0.4176 - val_loss: 3.8952\n",
      "Epoch 10/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4829 - loss: 1.1780 - val_accuracy: 0.4681 - val_loss: 4.4706\n",
      "Epoch 11/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4674 - loss: 1.1238 - val_accuracy: 0.4711 - val_loss: 4.0335\n",
      "Epoch 12/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5159 - loss: 1.1356 - val_accuracy: 0.4366 - val_loss: 4.2018\n",
      "Epoch 13/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5110 - loss: 1.1164 - val_accuracy: 0.5231 - val_loss: 4.1552\n",
      "Epoch 14/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5207 - loss: 1.1393 - val_accuracy: 0.4740 - val_loss: 4.2309\n",
      "Epoch 15/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5024 - loss: 1.1358 - val_accuracy: 0.4300 - val_loss: 4.2205\n",
      "Epoch 16/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4585 - loss: 1.1134 - val_accuracy: 0.5348 - val_loss: 4.0696\n",
      "Epoch 17/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 1.1429 - val_accuracy: 0.4337 - val_loss: 4.2320\n",
      "Epoch 18/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4016 - loss: 1.1758 - val_accuracy: 0.4725 - val_loss: 4.1561\n",
      "Epoch 19/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4899 - loss: 1.1474 - val_accuracy: 0.4293 - val_loss: 4.4478\n",
      "Epoch 20/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5016 - loss: 1.1375 - val_accuracy: 0.4491 - val_loss: 4.2573\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k_test3 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(64, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k_test3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Résumé du modèle\n",
    "model_trnctd_9k_test3.summary()\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k_test3.fit(X_train_truncated, y_train_truncated, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4433 - loss: 4.5311\n",
      "Précision sur l'ensemble de test : 0.4490\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.67      0.63      1015\n",
      "           A       0.07      0.14      0.10       152\n",
      "           O       0.31      0.12      0.18       483\n",
      "           ~       0.03      0.04      0.03        56\n",
      "\n",
      "    accuracy                           0.45      1706\n",
      "   macro avg       0.25      0.24      0.23      1706\n",
      "weighted avg       0.45      0.45      0.44      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k_test3.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k_test3.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2559 - loss: 239.1834 - val_accuracy: 0.2484 - val_loss: 154.4381\n",
      "Epoch 2/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2675 - loss: 143.1249 - val_accuracy: 0.2410 - val_loss: 108.5305\n",
      "Epoch 3/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3856 - loss: 61.6193 - val_accuracy: 0.2308 - val_loss: 90.9261\n",
      "Epoch 4/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4048 - loss: 46.1062 - val_accuracy: 0.2652 - val_loss: 71.0557\n",
      "Epoch 5/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4315 - loss: 25.5181 - val_accuracy: 0.2088 - val_loss: 59.2021\n",
      "Epoch 6/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4435 - loss: 15.6502 - val_accuracy: 0.2484 - val_loss: 44.5231\n",
      "Epoch 7/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4570 - loss: 13.9171 - val_accuracy: 0.2886 - val_loss: 35.8010\n",
      "Epoch 8/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4844 - loss: 11.8592 - val_accuracy: 0.3194 - val_loss: 29.9846\n",
      "Epoch 9/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5326 - loss: 6.7974 - val_accuracy: 0.3282 - val_loss: 28.5454\n",
      "Epoch 10/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5271 - loss: 8.1648 - val_accuracy: 0.3267 - val_loss: 34.6495\n",
      "Epoch 11/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5278 - loss: 8.6191 - val_accuracy: 0.3333 - val_loss: 24.9515\n",
      "Epoch 12/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5170 - loss: 6.7026 - val_accuracy: 0.2645 - val_loss: 22.9261\n",
      "Epoch 13/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5204 - loss: 4.1666 - val_accuracy: 0.3516 - val_loss: 14.4424\n",
      "Epoch 14/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5945 - loss: 1.9348 - val_accuracy: 0.4242 - val_loss: 11.7801\n",
      "Epoch 15/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6205 - loss: 1.9156 - val_accuracy: 0.4403 - val_loss: 10.6437\n",
      "Epoch 16/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6456 - loss: 1.2034 - val_accuracy: 0.3700 - val_loss: 13.3585\n",
      "Epoch 17/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5736 - loss: 2.5868 - val_accuracy: 0.4418 - val_loss: 11.7452\n",
      "Epoch 18/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5707 - loss: 2.6405 - val_accuracy: 0.4330 - val_loss: 10.9595\n",
      "Epoch 19/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4248 - loss: 15.6393 - val_accuracy: 0.4689 - val_loss: 9.8203\n",
      "Epoch 20/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 1.9314 - val_accuracy: 0.4667 - val_loss: 9.3210\n",
      "Epoch 21/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5950 - loss: 2.8478 - val_accuracy: 0.4659 - val_loss: 6.2163\n",
      "Epoch 22/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 1.4526 - val_accuracy: 0.4864 - val_loss: 6.0494\n",
      "Epoch 23/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6337 - loss: 1.1423 - val_accuracy: 0.4777 - val_loss: 5.2779\n",
      "Epoch 24/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6371 - loss: 1.0521 - val_accuracy: 0.4549 - val_loss: 6.8987\n",
      "Epoch 25/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 1.9849 - val_accuracy: 0.4821 - val_loss: 5.4737\n",
      "Epoch 26/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6084 - loss: 3.7354 - val_accuracy: 0.5084 - val_loss: 5.6476\n",
      "Epoch 27/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6177 - loss: 4.4727 - val_accuracy: 0.5223 - val_loss: 6.6563\n",
      "Epoch 28/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6367 - loss: 1.9471 - val_accuracy: 0.5297 - val_loss: 4.6081\n",
      "Epoch 29/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6377 - loss: 1.4183 - val_accuracy: 0.5231 - val_loss: 6.0124\n",
      "Epoch 30/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 2.1203 - val_accuracy: 0.5473 - val_loss: 4.0228\n",
      "Epoch 31/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6451 - loss: 1.3199 - val_accuracy: 0.5590 - val_loss: 4.9620\n",
      "Epoch 32/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6164 - loss: 1.7880 - val_accuracy: 0.5333 - val_loss: 3.2975\n",
      "Epoch 33/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6291 - loss: 1.5120 - val_accuracy: 0.5531 - val_loss: 2.6244\n",
      "Epoch 34/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6312 - loss: 1.1352 - val_accuracy: 0.5502 - val_loss: 2.5316\n",
      "Epoch 35/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6418 - loss: 1.5051 - val_accuracy: 0.5619 - val_loss: 2.9728\n",
      "Epoch 36/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 2.8646 - val_accuracy: 0.5619 - val_loss: 3.4576\n",
      "Epoch 37/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6282 - loss: 1.2679 - val_accuracy: 0.5685 - val_loss: 2.7455\n",
      "Epoch 38/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6443 - loss: 1.1909 - val_accuracy: 0.5736 - val_loss: 2.4448\n",
      "Epoch 39/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6252 - loss: 1.2117 - val_accuracy: 0.5744 - val_loss: 3.5433\n",
      "Epoch 40/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6339 - loss: 2.0123 - val_accuracy: 0.5568 - val_loss: 4.7879\n",
      "Epoch 41/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6200 - loss: 1.4855 - val_accuracy: 0.5736 - val_loss: 2.8837\n",
      "Epoch 42/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 1.2959 - val_accuracy: 0.5788 - val_loss: 2.7355\n",
      "Epoch 43/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 1.2796 - val_accuracy: 0.5817 - val_loss: 2.2944\n",
      "Epoch 44/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6312 - loss: 1.4596 - val_accuracy: 0.5780 - val_loss: 2.3045\n",
      "Epoch 45/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 1.2566 - val_accuracy: 0.5824 - val_loss: 2.1897\n",
      "Epoch 46/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6339 - loss: 1.1299 - val_accuracy: 0.5795 - val_loss: 2.1054\n",
      "Epoch 47/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 1.1790 - val_accuracy: 0.5795 - val_loss: 2.1257\n",
      "Epoch 48/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 1.1299 - val_accuracy: 0.5802 - val_loss: 2.1224\n",
      "Epoch 49/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6362 - loss: 1.1476 - val_accuracy: 0.5846 - val_loss: 2.0595\n",
      "Epoch 50/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6349 - loss: 1.1734 - val_accuracy: 0.5795 - val_loss: 2.0855\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k_test3_bis = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(64, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k_test3_bis.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k_test3_bis.fit(X_train_truncated, y_train_truncated, epochs=50, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5824 - loss: 1.9865\n",
      "Précision sur l'ensemble de test : 0.5809\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.97      0.74      1015\n",
      "           A       0.06      0.01      0.02       152\n",
      "           O       0.33      0.00      0.00       483\n",
      "           ~       0.06      0.02      0.03        56\n",
      "\n",
      "    accuracy                           0.58      1706\n",
      "   macro avg       0.26      0.25      0.20      1706\n",
      "weighted avg       0.46      0.58      0.44      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k_test3_bis.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k_test3_bis.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°4 truncated: Augmentation du nombre de neurone par couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,304,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,312,612</span> (8.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,312,612\u001b[0m (8.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,312,612</span> (8.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,312,612\u001b[0m (8.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.2629 - loss: 651.8776 - val_accuracy: 0.3304 - val_loss: 171.5834\n",
      "Epoch 2/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4769 - loss: 64.4707 - val_accuracy: 0.5128 - val_loss: 25.8799\n",
      "Epoch 3/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6008 - loss: 4.1252 - val_accuracy: 0.5516 - val_loss: 15.4352\n",
      "Epoch 4/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6171 - loss: 2.4273 - val_accuracy: 0.5568 - val_loss: 12.8738\n",
      "Epoch 5/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6284 - loss: 2.5779 - val_accuracy: 0.5619 - val_loss: 11.5994\n",
      "Epoch 6/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6365 - loss: 1.3781 - val_accuracy: 0.5619 - val_loss: 11.3584\n",
      "Epoch 7/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6360 - loss: 1.2716 - val_accuracy: 0.5641 - val_loss: 11.0956\n",
      "Epoch 8/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6227 - loss: 1.3445 - val_accuracy: 0.5663 - val_loss: 10.9545\n",
      "Epoch 9/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6211 - loss: 1.1673 - val_accuracy: 0.5656 - val_loss: 10.7503\n",
      "Epoch 10/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6367 - loss: 1.1701 - val_accuracy: 0.5590 - val_loss: 10.6539\n",
      "Epoch 11/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6255 - loss: 1.2953 - val_accuracy: 0.5678 - val_loss: 8.2299\n",
      "Epoch 12/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6339 - loss: 1.2069 - val_accuracy: 0.5700 - val_loss: 8.1658\n",
      "Epoch 13/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6387 - loss: 1.2592 - val_accuracy: 0.5685 - val_loss: 8.0951\n",
      "Epoch 14/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6339 - loss: 1.2416 - val_accuracy: 0.5685 - val_loss: 8.0136\n",
      "Epoch 15/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6340 - loss: 1.1947 - val_accuracy: 0.5685 - val_loss: 8.0004\n",
      "Epoch 16/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6328 - loss: 1.1506 - val_accuracy: 0.5678 - val_loss: 8.0228\n",
      "Epoch 17/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6284 - loss: 1.2179 - val_accuracy: 0.5685 - val_loss: 7.9940\n",
      "Epoch 18/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6349 - loss: 1.2118 - val_accuracy: 0.5692 - val_loss: 7.9876\n",
      "Epoch 19/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6284 - loss: 1.2119 - val_accuracy: 0.5700 - val_loss: 8.0057\n",
      "Epoch 20/20\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6330 - loss: 1.2097 - val_accuracy: 0.5692 - val_loss: 7.9719\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k_test4 = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k_test4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Résumé du modèle\n",
    "model_trnctd_9k_test4.summary()\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k_test4.fit(X_train_truncated, y_train_truncated, epochs=20, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 10.0775\n",
      "Précision sur l'ensemble de test : 0.5457\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.59      0.89      0.71      1015\n",
      "           A       0.12      0.04      0.06       152\n",
      "           O       0.23      0.03      0.05       483\n",
      "           ~       0.07      0.07      0.07        56\n",
      "\n",
      "    accuracy                           0.55      1706\n",
      "   macro avg       0.25      0.26      0.22      1706\n",
      "weighted avg       0.43      0.55      0.45      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k_test4.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k_test4.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.2638 - loss: 514.3107 - val_accuracy: 0.1919 - val_loss: 154.8622\n",
      "Epoch 2/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2235 - loss: 69.3639 - val_accuracy: 0.4410 - val_loss: 35.4544\n",
      "Epoch 3/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5485 - loss: 10.3234 - val_accuracy: 0.5004 - val_loss: 18.3164\n",
      "Epoch 4/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5856 - loss: 2.2776 - val_accuracy: 0.5201 - val_loss: 15.7895\n",
      "Epoch 5/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6291 - loss: 1.7566 - val_accuracy: 0.5311 - val_loss: 13.6171\n",
      "Epoch 6/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6243 - loss: 1.5295 - val_accuracy: 0.5341 - val_loss: 12.5277\n",
      "Epoch 7/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6353 - loss: 1.1864 - val_accuracy: 0.5377 - val_loss: 11.6272\n",
      "Epoch 8/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6346 - loss: 1.1642 - val_accuracy: 0.5392 - val_loss: 11.5090\n",
      "Epoch 9/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6384 - loss: 1.1799 - val_accuracy: 0.5385 - val_loss: 11.5383\n",
      "Epoch 10/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6363 - loss: 1.1956 - val_accuracy: 0.5429 - val_loss: 11.6366\n",
      "Epoch 11/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6347 - loss: 1.2209 - val_accuracy: 0.5436 - val_loss: 10.9831\n",
      "Epoch 12/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6476 - loss: 1.1232 - val_accuracy: 0.5363 - val_loss: 10.9236\n",
      "Epoch 13/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6417 - loss: 1.1886 - val_accuracy: 0.5326 - val_loss: 11.0510\n",
      "Epoch 14/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6317 - loss: 1.1695 - val_accuracy: 0.5385 - val_loss: 11.6885\n",
      "Epoch 15/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6514 - loss: 1.1933 - val_accuracy: 0.5495 - val_loss: 10.3702\n",
      "Epoch 16/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6342 - loss: 1.1713 - val_accuracy: 0.5429 - val_loss: 10.7516\n",
      "Epoch 17/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6323 - loss: 1.3680 - val_accuracy: 0.5516 - val_loss: 9.2500\n",
      "Epoch 18/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6453 - loss: 1.2132 - val_accuracy: 0.5582 - val_loss: 8.0037\n",
      "Epoch 19/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6445 - loss: 1.1109 - val_accuracy: 0.5560 - val_loss: 8.1160\n",
      "Epoch 20/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6364 - loss: 1.1354 - val_accuracy: 0.5546 - val_loss: 8.2309\n",
      "Epoch 21/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6466 - loss: 1.0745 - val_accuracy: 0.5546 - val_loss: 8.3163\n",
      "Epoch 22/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6291 - loss: 1.3765 - val_accuracy: 0.5480 - val_loss: 9.6106\n",
      "Epoch 23/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6293 - loss: 1.9322 - val_accuracy: 0.5744 - val_loss: 6.9314\n",
      "Epoch 24/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6182 - loss: 2.0993 - val_accuracy: 0.5780 - val_loss: 4.0113\n",
      "Epoch 25/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6076 - loss: 2.1302 - val_accuracy: 0.5824 - val_loss: 4.8671\n",
      "Epoch 26/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6108 - loss: 1.5140 - val_accuracy: 0.5897 - val_loss: 2.6336\n",
      "Epoch 27/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6001 - loss: 1.5653 - val_accuracy: 0.5883 - val_loss: 2.7129\n",
      "Epoch 28/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6112 - loss: 1.5796 - val_accuracy: 0.5912 - val_loss: 2.5786\n",
      "Epoch 29/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6071 - loss: 1.3168 - val_accuracy: 0.5846 - val_loss: 2.6380\n",
      "Epoch 30/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6221 - loss: 1.3414 - val_accuracy: 0.5868 - val_loss: 2.4344\n",
      "Epoch 31/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6084 - loss: 1.3038 - val_accuracy: 0.5846 - val_loss: 2.4764\n",
      "Epoch 32/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6141 - loss: 1.4124 - val_accuracy: 0.5846 - val_loss: 2.4395\n",
      "Epoch 33/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6080 - loss: 1.3070 - val_accuracy: 0.5853 - val_loss: 2.4183\n",
      "Epoch 34/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6210 - loss: 1.3239 - val_accuracy: 0.5868 - val_loss: 2.4154\n",
      "Epoch 35/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6125 - loss: 1.3177 - val_accuracy: 0.5868 - val_loss: 2.4300\n",
      "Epoch 36/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6281 - loss: 1.2433 - val_accuracy: 0.5875 - val_loss: 2.4279\n",
      "Epoch 37/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6093 - loss: 1.2880 - val_accuracy: 0.5875 - val_loss: 2.4295\n",
      "Epoch 38/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6158 - loss: 1.2590 - val_accuracy: 0.5875 - val_loss: 2.4286\n",
      "Epoch 39/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6136 - loss: 1.2776 - val_accuracy: 0.5875 - val_loss: 2.4303\n",
      "Epoch 40/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6093 - loss: 1.2814 - val_accuracy: 0.5875 - val_loss: 2.4353\n",
      "Epoch 41/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6185 - loss: 1.3287 - val_accuracy: 0.5875 - val_loss: 2.4368\n",
      "Epoch 42/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6112 - loss: 1.2991 - val_accuracy: 0.5875 - val_loss: 2.4400\n",
      "Epoch 43/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6123 - loss: 1.2983 - val_accuracy: 0.5875 - val_loss: 2.4422\n",
      "Epoch 44/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6132 - loss: 1.3050 - val_accuracy: 0.5875 - val_loss: 2.4432\n",
      "Epoch 45/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5980 - loss: 1.3650 - val_accuracy: 0.5853 - val_loss: 2.4434\n",
      "Epoch 46/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6078 - loss: 1.3238 - val_accuracy: 0.5846 - val_loss: 2.4994\n",
      "Epoch 47/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6185 - loss: 1.2955 - val_accuracy: 0.5853 - val_loss: 2.5618\n",
      "Epoch 48/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6139 - loss: 1.3319 - val_accuracy: 0.5883 - val_loss: 2.4446\n",
      "Epoch 49/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6197 - loss: 1.3102 - val_accuracy: 0.5868 - val_loss: 2.4286\n",
      "Epoch 50/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6117 - loss: 1.2968 - val_accuracy: 0.5861 - val_loss: 2.5098\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_trnctd_9k_test4_bis = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_trnctd_9k_test4_bis.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_truncated), y=y_train_truncated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_truncated = model_trnctd_9k_test4_bis.fit(X_train_truncated, y_train_truncated, epochs=50, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 2.9884\n",
      "Précision sur l'ensemble de test : 0.5897\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.99      0.74      1015\n",
      "           A       0.00      0.00      0.00       152\n",
      "           O       0.50      0.00      0.00       483\n",
      "           ~       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.59      1706\n",
      "   macro avg       0.27      0.25      0.19      1706\n",
      "weighted avg       0.50      0.59      0.44      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_trnctd_9k_test4_bis.evaluate(X_test_truncated, y_test_truncated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_trnctd_9k_test4_bis.predict(X_test_truncated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_truncated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°1 interpolated: Augmentation du nombre d'epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2465 - loss: 495.0851 - val_accuracy: 0.2125 - val_loss: 278.2266\n",
      "Epoch 2/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3138 - loss: 147.7290 - val_accuracy: 0.2447 - val_loss: 113.1915\n",
      "Epoch 3/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3399 - loss: 60.7825 - val_accuracy: 0.2425 - val_loss: 101.9273\n",
      "Epoch 4/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3738 - loss: 22.6244 - val_accuracy: 0.2916 - val_loss: 47.7620\n",
      "Epoch 5/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4068 - loss: 6.4646 - val_accuracy: 0.2967 - val_loss: 34.2193\n",
      "Epoch 6/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4095 - loss: 4.4695 - val_accuracy: 0.4366 - val_loss: 33.0550\n",
      "Epoch 7/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5658 - loss: 4.0388 - val_accuracy: 0.4725 - val_loss: 27.0284\n",
      "Epoch 8/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5917 - loss: 2.5910 - val_accuracy: 0.4813 - val_loss: 22.4398\n",
      "Epoch 9/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6152 - loss: 7.1214 - val_accuracy: 0.5084 - val_loss: 20.2925\n",
      "Epoch 10/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6293 - loss: 1.4788 - val_accuracy: 0.5018 - val_loss: 18.7295\n",
      "Epoch 11/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6199 - loss: 1.1221 - val_accuracy: 0.5172 - val_loss: 17.9680\n",
      "Epoch 12/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6306 - loss: 0.9880 - val_accuracy: 0.5121 - val_loss: 17.7278\n",
      "Epoch 13/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6524 - loss: 0.9988 - val_accuracy: 0.5370 - val_loss: 17.3573\n",
      "Epoch 14/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6565 - loss: 0.9921 - val_accuracy: 0.5260 - val_loss: 17.2355\n",
      "Epoch 15/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6584 - loss: 0.9299 - val_accuracy: 0.5429 - val_loss: 17.2463\n",
      "Epoch 16/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6360 - loss: 0.9750 - val_accuracy: 0.5238 - val_loss: 17.2524\n",
      "Epoch 17/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4149 - loss: 0.9789 - val_accuracy: 0.5048 - val_loss: 17.6217\n",
      "Epoch 18/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5210 - loss: 4.2738 - val_accuracy: 0.4945 - val_loss: 20.4822\n",
      "Epoch 19/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6033 - loss: 3.9990 - val_accuracy: 0.1341 - val_loss: 10.2105\n",
      "Epoch 20/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2920 - loss: 2.0274 - val_accuracy: 0.5333 - val_loss: 9.8914\n",
      "Epoch 21/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5602 - loss: 1.9209 - val_accuracy: 0.1201 - val_loss: 20.2084\n",
      "Epoch 22/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2317 - loss: 4.3747 - val_accuracy: 0.5648 - val_loss: 8.0496\n",
      "Epoch 23/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6237 - loss: 2.3664 - val_accuracy: 0.5656 - val_loss: 7.9855\n",
      "Epoch 24/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6419 - loss: 1.2581 - val_accuracy: 0.5656 - val_loss: 7.9260\n",
      "Epoch 25/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6274 - loss: 1.3976 - val_accuracy: 0.5707 - val_loss: 7.5145\n",
      "Epoch 26/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6347 - loss: 1.2258 - val_accuracy: 0.5648 - val_loss: 6.9280\n",
      "Epoch 27/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6159 - loss: 2.6031 - val_accuracy: 0.5678 - val_loss: 7.1231\n",
      "Epoch 28/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6320 - loss: 2.0808 - val_accuracy: 0.5641 - val_loss: 8.8542\n",
      "Epoch 29/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6168 - loss: 2.1940 - val_accuracy: 0.5846 - val_loss: 8.7676\n",
      "Epoch 30/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6126 - loss: 5.1385 - val_accuracy: 0.5868 - val_loss: 4.9659\n",
      "Epoch 31/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6046 - loss: 1.4753 - val_accuracy: 0.5853 - val_loss: 4.5935\n",
      "Epoch 32/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6073 - loss: 1.3754 - val_accuracy: 0.5875 - val_loss: 3.6826\n",
      "Epoch 33/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6028 - loss: 1.3095 - val_accuracy: 0.0901 - val_loss: 3.9634\n",
      "Epoch 34/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2125 - loss: 1.2616 - val_accuracy: 0.0923 - val_loss: 3.9733\n",
      "Epoch 35/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2549 - loss: 1.2827 - val_accuracy: 0.0901 - val_loss: 3.9777\n",
      "Epoch 36/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1147 - loss: 1.3021 - val_accuracy: 0.0894 - val_loss: 3.9803\n",
      "Epoch 37/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1154 - loss: 1.2933 - val_accuracy: 0.0901 - val_loss: 3.9889\n",
      "Epoch 38/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1222 - loss: 1.2829 - val_accuracy: 0.0916 - val_loss: 4.0131\n",
      "Epoch 39/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1263 - loss: 1.3512 - val_accuracy: 0.0908 - val_loss: 4.0882\n",
      "Epoch 40/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1703 - loss: 1.2918 - val_accuracy: 0.0886 - val_loss: 4.5046\n",
      "Epoch 41/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4119 - loss: 1.2732 - val_accuracy: 0.0886 - val_loss: 4.3794\n",
      "Epoch 42/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3378 - loss: 1.2689 - val_accuracy: 0.0894 - val_loss: 4.0956\n",
      "Epoch 43/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3635 - loss: 1.2804 - val_accuracy: 0.0916 - val_loss: 3.9978\n",
      "Epoch 44/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1857 - loss: 1.2843 - val_accuracy: 0.0908 - val_loss: 3.9837\n",
      "Epoch 45/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1104 - loss: 1.3131 - val_accuracy: 0.5861 - val_loss: 4.0267\n",
      "Epoch 46/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6211 - loss: 1.2591 - val_accuracy: 0.0894 - val_loss: 3.9822\n",
      "Epoch 47/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3137 - loss: 1.3277 - val_accuracy: 0.5846 - val_loss: 4.0153\n",
      "Epoch 48/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5555 - loss: 1.3038 - val_accuracy: 0.5824 - val_loss: 4.0603\n",
      "Epoch 49/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3734 - loss: 3.3306 - val_accuracy: 0.0864 - val_loss: 2.8673\n",
      "Epoch 50/50\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3045 - loss: 1.3870 - val_accuracy: 0.0894 - val_loss: 2.8668\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_interpltd_9k_test1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_interpolated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_interpltd_9k_test1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_interpolated), y=y_train_interpolated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_interpolated = model_interpltd_9k_test1.fit(X_train_interpolated, y_train_interpolated, epochs=50, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0893 - loss: 2.1355\n",
      "Précision sur l'ensemble de test : 0.0879\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00      1015\n",
      "           A       0.09      0.98      0.16       152\n",
      "           O       0.07      0.00      0.00       483\n",
      "           ~       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.09      1706\n",
      "   macro avg       0.04      0.25      0.04      1706\n",
      "weighted avg       0.03      0.09      0.02      1706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_interpltd_9k_test1.evaluate(X_test_interpolated, y_test_interpolated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_interpltd_9k_test1.predict(X_test_interpolated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_interpolated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°2 interpolated: Augmentation du nombre de couches (de une à deux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_80 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,152,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_81 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,162,596</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,162,596\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,162,596</span> (4.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,162,596\u001b[0m (4.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2769 - loss: 218.2848 - val_accuracy: 0.2278 - val_loss: 118.5630\n",
      "Epoch 2/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2758 - loss: 90.8396 - val_accuracy: 0.2366 - val_loss: 24.2111\n",
      "Epoch 3/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2929 - loss: 15.8383 - val_accuracy: 0.2652 - val_loss: 9.8965\n",
      "Epoch 4/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3172 - loss: 2.4269 - val_accuracy: 0.2630 - val_loss: 12.0606\n",
      "Epoch 5/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3093 - loss: 2.7246 - val_accuracy: 0.2886 - val_loss: 6.9065\n",
      "Epoch 6/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4493 - loss: 1.5702 - val_accuracy: 0.5538 - val_loss: 5.2554\n",
      "Epoch 7/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5585 - loss: 1.2693 - val_accuracy: 0.0945 - val_loss: 5.0875\n",
      "Epoch 8/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3703 - loss: 1.2110 - val_accuracy: 0.0960 - val_loss: 4.9427\n",
      "Epoch 9/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1283 - loss: 1.2605 - val_accuracy: 0.0923 - val_loss: 4.9706\n",
      "Epoch 10/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1338 - loss: 1.2501 - val_accuracy: 0.1011 - val_loss: 4.8672\n",
      "Epoch 11/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1388 - loss: 1.1973 - val_accuracy: 0.0945 - val_loss: 4.8909\n",
      "Epoch 12/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2191 - loss: 1.2618 - val_accuracy: 0.0930 - val_loss: 4.7929\n",
      "Epoch 13/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2527 - loss: 1.2206 - val_accuracy: 0.1062 - val_loss: 4.8034\n",
      "Epoch 14/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1292 - loss: 1.2504 - val_accuracy: 0.1070 - val_loss: 4.7959\n",
      "Epoch 15/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1454 - loss: 1.2238 - val_accuracy: 0.0967 - val_loss: 4.8155\n",
      "Epoch 16/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1367 - loss: 1.2148 - val_accuracy: 0.1011 - val_loss: 4.8096\n",
      "Epoch 17/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2503 - loss: 1.2036 - val_accuracy: 0.0930 - val_loss: 4.8062\n",
      "Epoch 18/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1321 - loss: 1.2566 - val_accuracy: 0.1055 - val_loss: 4.8447\n",
      "Epoch 19/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1486 - loss: 1.2167 - val_accuracy: 0.5553 - val_loss: 4.8546\n",
      "Epoch 20/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4187 - loss: 1.2118 - val_accuracy: 0.1004 - val_loss: 4.3632\n",
      "Epoch 21/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1625 - loss: 1.2644 - val_accuracy: 0.5546 - val_loss: 4.2644\n",
      "Epoch 22/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6046 - loss: 1.2740 - val_accuracy: 0.5619 - val_loss: 3.8691\n",
      "Epoch 23/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 1.1764 - val_accuracy: 0.5604 - val_loss: 3.6702\n",
      "Epoch 24/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 1.2801 - val_accuracy: 0.5619 - val_loss: 3.7281\n",
      "Epoch 25/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6198 - loss: 1.2214 - val_accuracy: 0.5692 - val_loss: 2.1123\n",
      "Epoch 26/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 1.3030 - val_accuracy: 0.5853 - val_loss: 1.3422\n",
      "Epoch 27/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 1.2934 - val_accuracy: 0.5890 - val_loss: 1.3279\n",
      "Epoch 28/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5453 - loss: 1.3309 - val_accuracy: 0.5883 - val_loss: 1.3395\n",
      "Epoch 29/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4522 - loss: 1.3708 - val_accuracy: 0.5853 - val_loss: 1.3755\n",
      "Epoch 30/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4951 - loss: 1.4094 - val_accuracy: 0.5861 - val_loss: 1.3520\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_interpltd_9k_test2 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_interpolated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(64, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_interpltd_9k_test2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Résumé du modèle\n",
    "model_interpltd_9k_test2.summary()\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_interpolated), y=y_train_interpolated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_interpolated = model_interpltd_9k_test2.fit(X_train_interpolated, y_train_interpolated, epochs=30, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5870 - loss: 2.0162\n",
      "Précision sur l'ensemble de test : 0.5862\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.98      0.74      1015\n",
      "           A       0.00      0.00      0.00       152\n",
      "           O       0.50      0.01      0.01       483\n",
      "           ~       0.06      0.04      0.04        56\n",
      "\n",
      "    accuracy                           0.59      1706\n",
      "   macro avg       0.29      0.26      0.20      1706\n",
      "weighted avg       0.50      0.59      0.45      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_interpltd_9k_test2.evaluate(X_test_interpolated, y_test_interpolated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_interpltd_9k_test2.predict(X_test_interpolated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_interpolated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST N°3 interpolated: Augmentation du nombre de neurone par couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albus\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,304,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,312,612</span> (8.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,312,612\u001b[0m (8.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,312,612</span> (8.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,312,612\u001b[0m (8.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2420 - loss: 511.6327 - val_accuracy: 0.1949 - val_loss: 74.9022\n",
      "Epoch 2/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3864 - loss: 32.6347 - val_accuracy: 0.4681 - val_loss: 20.5146\n",
      "Epoch 3/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5434 - loss: 4.9647 - val_accuracy: 0.5136 - val_loss: 13.3748\n",
      "Epoch 4/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5813 - loss: 2.1209 - val_accuracy: 0.5070 - val_loss: 26.5746\n",
      "Epoch 5/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5251 - loss: 4.2300 - val_accuracy: 0.5480 - val_loss: 11.0929\n",
      "Epoch 6/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 1.3597 - val_accuracy: 0.5473 - val_loss: 10.4890\n",
      "Epoch 7/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6300 - loss: 1.2329 - val_accuracy: 0.5487 - val_loss: 10.2719\n",
      "Epoch 8/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6365 - loss: 1.1585 - val_accuracy: 0.5429 - val_loss: 10.2810\n",
      "Epoch 9/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6244 - loss: 1.1789 - val_accuracy: 0.5495 - val_loss: 10.1549\n",
      "Epoch 10/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6390 - loss: 1.1456 - val_accuracy: 0.5414 - val_loss: 10.0762\n",
      "Epoch 11/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6359 - loss: 1.1734 - val_accuracy: 0.5443 - val_loss: 10.0648\n",
      "Epoch 12/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6268 - loss: 1.3398 - val_accuracy: 0.5407 - val_loss: 12.7212\n",
      "Epoch 13/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5998 - loss: 5.0929 - val_accuracy: 0.5729 - val_loss: 3.6870\n",
      "Epoch 14/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6179 - loss: 2.6517 - val_accuracy: 0.5758 - val_loss: 3.6457\n",
      "Epoch 15/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6148 - loss: 1.3414 - val_accuracy: 0.2952 - val_loss: 3.5184\n",
      "Epoch 16/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3276 - loss: 1.2943 - val_accuracy: 0.2952 - val_loss: 3.6005\n",
      "Epoch 17/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5134 - loss: 1.2326 - val_accuracy: 0.2930 - val_loss: 3.5876\n",
      "Epoch 18/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4823 - loss: 1.2443 - val_accuracy: 0.2923 - val_loss: 3.5889\n",
      "Epoch 19/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3249 - loss: 1.2651 - val_accuracy: 0.2945 - val_loss: 3.3657\n",
      "Epoch 20/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3562 - loss: 1.2679 - val_accuracy: 0.2945 - val_loss: 3.3856\n",
      "Epoch 21/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5542 - loss: 1.2720 - val_accuracy: 0.2923 - val_loss: 3.3790\n",
      "Epoch 22/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3697 - loss: 1.2419 - val_accuracy: 0.2901 - val_loss: 3.3493\n",
      "Epoch 23/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4631 - loss: 1.2189 - val_accuracy: 0.5758 - val_loss: 3.3542\n",
      "Epoch 24/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6216 - loss: 1.2588 - val_accuracy: 0.5758 - val_loss: 3.3373\n",
      "Epoch 25/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5362 - loss: 1.2667 - val_accuracy: 0.5751 - val_loss: 3.3394\n",
      "Epoch 26/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4741 - loss: 1.2664 - val_accuracy: 0.5766 - val_loss: 3.2740\n",
      "Epoch 27/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6234 - loss: 1.2433 - val_accuracy: 0.5714 - val_loss: 3.4756\n",
      "Epoch 28/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6210 - loss: 1.2705 - val_accuracy: 0.5751 - val_loss: 3.3917\n",
      "Epoch 29/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6192 - loss: 1.2756 - val_accuracy: 0.5780 - val_loss: 3.2480\n",
      "Epoch 30/30\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6181 - loss: 1.2380 - val_accuracy: 0.5744 - val_loss: 3.2469\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle MLP\n",
    "model_interpltd_9k_test3 = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(X_train_truncated.shape[1],)),  # Couche d'entrée\n",
    "    layers.Dense(32, activation='relu'),  # Couche cachée\n",
    "    layers.Dense(4, activation='softmax')  # Couche de sortie (4 classes)\n",
    "])\n",
    "\n",
    "\n",
    "model_interpltd_9k_test3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Résumé du modèle\n",
    "model_interpltd_9k_test3.summary()\n",
    "\n",
    "# Calculer le poids de classe pour gérer le déséquilibre\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_interpolated), y=y_train_interpolated)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_interpolated = model_interpltd_9k_test3.fit(X_train_interpolated, y_train_interpolated, epochs=30, batch_size=32, validation_split=0.2, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5609 - loss: 4.1180\n",
      "Précision sur l'ensemble de test : 0.5645\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.59      0.94      0.73      1015\n",
      "           A       0.05      0.01      0.02       152\n",
      "           O       0.23      0.01      0.01       483\n",
      "           ~       0.02      0.02      0.02        56\n",
      "\n",
      "    accuracy                           0.56      1706\n",
      "   macro avg       0.23      0.25      0.20      1706\n",
      "weighted avg       0.42      0.56      0.44      1706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model_interpltd_9k_test3.evaluate(X_test_interpolated, y_test_interpolated)\n",
    "print(f'Précision sur l\\'ensemble de test : {test_accuracy:.4f}')\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model_interpltd_9k_test3.predict(X_test_interpolated)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "report = classification_report(y_test_interpolated, predicted_classes, target_names=['N', 'A', 'O', '~'])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
